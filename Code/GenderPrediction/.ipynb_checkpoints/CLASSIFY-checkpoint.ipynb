{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm\n",
    "from ipynb.fs.full.PROCESSING_DATASET import splitDataset\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import pickle\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RF_model.sav']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=splitDataset()\n",
    "x=data.loadFeatures()\n",
    "y=data.loadLabels()\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0,random_state=None)\n",
    "RF= RandomForestClassifier( )\n",
    "RF.fit(x_train,y_train.ravel())\n",
    "# save the model to disk\n",
    "filename = 'RF_model.sav'\n",
    "joblib.dump(RF, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LR_model.sav']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=splitDataset()\n",
    "x=data.loadFeatures()\n",
    "y=data.loadLabels()\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0,random_state=None)\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(x_train, y_train.ravel())\n",
    "# save the model to disk\n",
    "filename = 'LR_model.sav'\n",
    "joblib.dump(logreg, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GNB_model.sav']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=splitDataset()\n",
    "x=data.loadFeatures()\n",
    "y=data.loadLabels()\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0,random_state=None)\n",
    "GNB = GaussianNB()\n",
    "GNB.fit(x_train, y_train.ravel())\n",
    "# save the model to disk\n",
    "filename = 'GNB_model.sav'\n",
    "joblib.dump(GNB, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SVM_model.sav']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=splitDataset()\n",
    "x=data.loadFeatures()\n",
    "y=data.loadLabels()\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0,random_state=None)\n",
    "SVM= svm.SVC(kernel='linear') # Linear Kernel\n",
    "SVM.fit(x_train, y_train.ravel())\n",
    "# save the model to disk\n",
    "filename = 'SVM_model.sav'\n",
    "joblib.dump(SVM, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import History\n",
    "from keras.utils import plot_model\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1300\n",
      "1099/1099 [==============================] - 1s 1ms/step - loss: 0.6946 - acc: 0.4759\n",
      "Epoch 2/1300\n",
      "1099/1099 [==============================] - 1s 466us/step - loss: 0.6909 - acc: 0.5387\n",
      "Epoch 3/1300\n",
      "1099/1099 [==============================] - 1s 517us/step - loss: 0.6872 - acc: 0.5833\n",
      "Epoch 4/1300\n",
      "1099/1099 [==============================] - 1s 715us/step - loss: 0.6837 - acc: 0.6406\n",
      "Epoch 5/1300\n",
      "1099/1099 [==============================] - 1s 499us/step - loss: 0.6804 - acc: 0.6561\n",
      "Epoch 6/1300\n",
      "1099/1099 [==============================] - 1s 523us/step - loss: 0.6770 - acc: 0.6706\n",
      "Epoch 7/1300\n",
      "1099/1099 [==============================] - 1s 610us/step - loss: 0.6737 - acc: 0.7052\n",
      "Epoch 8/1300\n",
      "1099/1099 [==============================] - 1s 535us/step - loss: 0.6705 - acc: 0.6979\n",
      "Epoch 9/1300\n",
      "1099/1099 [==============================] - 1s 456us/step - loss: 0.6667 - acc: 0.6979\n",
      "Epoch 10/1300\n",
      "1099/1099 [==============================] - 1s 489us/step - loss: 0.6629 - acc: 0.7006\n",
      "Epoch 11/1300\n",
      "1099/1099 [==============================] - 0s 441us/step - loss: 0.6593 - acc: 0.7179\n",
      "Epoch 12/1300\n",
      "1099/1099 [==============================] - 1s 478us/step - loss: 0.6553 - acc: 0.7179\n",
      "Epoch 13/1300\n",
      "1099/1099 [==============================] - 0s 444us/step - loss: 0.6514 - acc: 0.7225\n",
      "Epoch 14/1300\n",
      "1099/1099 [==============================] - 1s 498us/step - loss: 0.6472 - acc: 0.7188\n",
      "Epoch 15/1300\n",
      "1099/1099 [==============================] - 0s 295us/step - loss: 0.6427 - acc: 0.7325\n",
      "Epoch 16/1300\n",
      "1099/1099 [==============================] - 0s 419us/step - loss: 0.6383 - acc: 0.7298\n",
      "Epoch 17/1300\n",
      "1099/1099 [==============================] - 0s 370us/step - loss: 0.6338 - acc: 0.7288\n",
      "Epoch 18/1300\n",
      "1099/1099 [==============================] - 0s 229us/step - loss: 0.6292 - acc: 0.7279\n",
      "Epoch 19/1300\n",
      "1099/1099 [==============================] - 0s 218us/step - loss: 0.6238 - acc: 0.7343\n",
      "Epoch 20/1300\n",
      "1099/1099 [==============================] - 0s 215us/step - loss: 0.6193 - acc: 0.7270\n",
      "Epoch 21/1300\n",
      "1099/1099 [==============================] - 0s 226us/step - loss: 0.6146 - acc: 0.7279\n",
      "Epoch 22/1300\n",
      "1099/1099 [==============================] - 0s 224us/step - loss: 0.6088 - acc: 0.7316\n",
      "Epoch 23/1300\n",
      "1099/1099 [==============================] - 0s 203us/step - loss: 0.6037 - acc: 0.7316\n",
      "Epoch 24/1300\n",
      "1099/1099 [==============================] - 0s 217us/step - loss: 0.5980 - acc: 0.7261\n",
      "Epoch 25/1300\n",
      "1099/1099 [==============================] - 0s 208us/step - loss: 0.5931 - acc: 0.7370\n",
      "Epoch 26/1300\n",
      "1099/1099 [==============================] - 0s 217us/step - loss: 0.5875 - acc: 0.7370\n",
      "Epoch 27/1300\n",
      "1099/1099 [==============================] - 0s 218us/step - loss: 0.5821 - acc: 0.7343\n",
      "Epoch 28/1300\n",
      "1099/1099 [==============================] - 0s 232us/step - loss: 0.5761 - acc: 0.7416\n",
      "Epoch 29/1300\n",
      "1099/1099 [==============================] - 0s 241us/step - loss: 0.5708 - acc: 0.7352\n",
      "Epoch 30/1300\n",
      "1099/1099 [==============================] - 0s 233us/step - loss: 0.5655 - acc: 0.7434\n",
      "Epoch 31/1300\n",
      "1099/1099 [==============================] - 0s 273us/step - loss: 0.5606 - acc: 0.7379\n",
      "Epoch 32/1300\n",
      "1099/1099 [==============================] - 0s 284us/step - loss: 0.5559 - acc: 0.7480\n",
      "Epoch 33/1300\n",
      "1099/1099 [==============================] - 0s 253us/step - loss: 0.5488 - acc: 0.7452\n",
      "Epoch 34/1300\n",
      "1099/1099 [==============================] - 0s 240us/step - loss: 0.5468 - acc: 0.7416\n",
      "Epoch 35/1300\n",
      "1099/1099 [==============================] - 0s 218us/step - loss: 0.5418 - acc: 0.7507\n",
      "Epoch 36/1300\n",
      "1099/1099 [==============================] - 0s 207us/step - loss: 0.5363 - acc: 0.7498\n",
      "Epoch 37/1300\n",
      "1099/1099 [==============================] - 0s 223us/step - loss: 0.5322 - acc: 0.7516\n",
      "Epoch 38/1300\n",
      "1099/1099 [==============================] - 0s 226us/step - loss: 0.5284 - acc: 0.7552\n",
      "Epoch 39/1300\n",
      "1099/1099 [==============================] - 0s 242us/step - loss: 0.5239 - acc: 0.7516\n",
      "Epoch 40/1300\n",
      "1099/1099 [==============================] - 0s 213us/step - loss: 0.5203 - acc: 0.7589\n",
      "Epoch 41/1300\n",
      "1099/1099 [==============================] - 0s 207us/step - loss: 0.5147 - acc: 0.7516\n",
      "Epoch 42/1300\n",
      "1099/1099 [==============================] - 0s 217us/step - loss: 0.5173 - acc: 0.7461\n",
      "Epoch 43/1300\n",
      "1099/1099 [==============================] - 0s 268us/step - loss: 0.5102 - acc: 0.7571\n",
      "Epoch 44/1300\n",
      "1099/1099 [==============================] - 0s 245us/step - loss: 0.5067 - acc: 0.7552\n",
      "Epoch 45/1300\n",
      "1099/1099 [==============================] - 0s 227us/step - loss: 0.5039 - acc: 0.7480\n",
      "Epoch 46/1300\n",
      "1099/1099 [==============================] - 0s 220us/step - loss: 0.5005 - acc: 0.7643\n",
      "Epoch 47/1300\n",
      "1099/1099 [==============================] - 0s 226us/step - loss: 0.4994 - acc: 0.7552\n",
      "Epoch 48/1300\n",
      "1099/1099 [==============================] - 0s 211us/step - loss: 0.4965 - acc: 0.7543\n",
      "Epoch 49/1300\n",
      "1099/1099 [==============================] - 0s 223us/step - loss: 0.4931 - acc: 0.7516\n",
      "Epoch 50/1300\n",
      "1099/1099 [==============================] - 0s 253us/step - loss: 0.4916 - acc: 0.7480\n",
      "Epoch 51/1300\n",
      "1099/1099 [==============================] - 0s 261us/step - loss: 0.4908 - acc: 0.7480\n",
      "Epoch 52/1300\n",
      "1099/1099 [==============================] - 0s 253us/step - loss: 0.4884 - acc: 0.7534\n",
      "Epoch 53/1300\n",
      "1099/1099 [==============================] - 0s 221us/step - loss: 0.4841 - acc: 0.7662\n",
      "Epoch 54/1300\n",
      "1099/1099 [==============================] - 0s 275us/step - loss: 0.4844 - acc: 0.7571\n",
      "Epoch 55/1300\n",
      "1099/1099 [==============================] - 0s 254us/step - loss: 0.4816 - acc: 0.7607\n",
      "Epoch 56/1300\n",
      "1099/1099 [==============================] - 0s 279us/step - loss: 0.4848 - acc: 0.7561\n",
      "Epoch 57/1300\n",
      "1099/1099 [==============================] - 0s 240us/step - loss: 0.4797 - acc: 0.7571\n",
      "Epoch 58/1300\n",
      "1099/1099 [==============================] - 0s 218us/step - loss: 0.4783 - acc: 0.7543\n",
      "Epoch 59/1300\n",
      "1099/1099 [==============================] - 0s 213us/step - loss: 0.4766 - acc: 0.7580\n",
      "Epoch 60/1300\n",
      "1099/1099 [==============================] - 0s 238us/step - loss: 0.4743 - acc: 0.7662\n",
      "Epoch 61/1300\n",
      "1099/1099 [==============================] - 0s 234us/step - loss: 0.4749 - acc: 0.7470\n",
      "Epoch 62/1300\n",
      "1099/1099 [==============================] - 0s 217us/step - loss: 0.4736 - acc: 0.7580\n",
      "Epoch 63/1300\n",
      "1099/1099 [==============================] - 0s 231us/step - loss: 0.4710 - acc: 0.7543\n",
      "Epoch 64/1300\n",
      "1099/1099 [==============================] - 0s 218us/step - loss: 0.4736 - acc: 0.7616\n",
      "Epoch 65/1300\n",
      "1099/1099 [==============================] - 0s 232us/step - loss: 0.4690 - acc: 0.7571\n",
      "Epoch 66/1300\n",
      "1099/1099 [==============================] - 0s 242us/step - loss: 0.4703 - acc: 0.7534\n",
      "Epoch 67/1300\n",
      "1099/1099 [==============================] - 0s 266us/step - loss: 0.4703 - acc: 0.7580\n",
      "Epoch 68/1300\n",
      "1099/1099 [==============================] - 0s 220us/step - loss: 0.4673 - acc: 0.7525\n",
      "Epoch 69/1300\n",
      "1099/1099 [==============================] - 0s 212us/step - loss: 0.4683 - acc: 0.7552\n",
      "Epoch 70/1300\n",
      "1099/1099 [==============================] - 0s 213us/step - loss: 0.4676 - acc: 0.7616\n",
      "Epoch 71/1300\n",
      "1099/1099 [==============================] - 0s 216us/step - loss: 0.4678 - acc: 0.7534\n",
      "Epoch 72/1300\n",
      "1099/1099 [==============================] - 0s 211us/step - loss: 0.4653 - acc: 0.7552\n",
      "Epoch 73/1300\n",
      "1099/1099 [==============================] - 0s 257us/step - loss: 0.4659 - acc: 0.7552\n",
      "Epoch 74/1300\n",
      "1099/1099 [==============================] - 0s 340us/step - loss: 0.4658 - acc: 0.7552\n",
      "Epoch 75/1300\n",
      "1099/1099 [==============================] - 0s 224us/step - loss: 0.4633 - acc: 0.7616\n",
      "Epoch 76/1300\n",
      "1099/1099 [==============================] - 0s 241us/step - loss: 0.4622 - acc: 0.7634\n",
      "Epoch 77/1300\n",
      "1099/1099 [==============================] - 0s 238us/step - loss: 0.4635 - acc: 0.7625\n",
      "Epoch 78/1300\n",
      "1099/1099 [==============================] - 0s 235us/step - loss: 0.4611 - acc: 0.7634\n",
      "Epoch 79/1300\n",
      "1099/1099 [==============================] - 0s 294us/step - loss: 0.4613 - acc: 0.7589\n",
      "Epoch 80/1300\n",
      "1099/1099 [==============================] - 0s 299us/step - loss: 0.4591 - acc: 0.7662\n",
      "Epoch 81/1300\n",
      "1099/1099 [==============================] - 0s 406us/step - loss: 0.4606 - acc: 0.7552\n",
      "Epoch 82/1300\n",
      "1099/1099 [==============================] - 0s 307us/step - loss: 0.4591 - acc: 0.7571\n",
      "Epoch 83/1300\n",
      "1099/1099 [==============================] - 0s 274us/step - loss: 0.4572 - acc: 0.7498\n",
      "Epoch 84/1300\n",
      "1099/1099 [==============================] - 0s 273us/step - loss: 0.4595 - acc: 0.7662\n",
      "Epoch 85/1300\n",
      "1099/1099 [==============================] - 0s 271us/step - loss: 0.4578 - acc: 0.7643\n",
      "Epoch 86/1300\n",
      "1099/1099 [==============================] - 0s 269us/step - loss: 0.4586 - acc: 0.7680\n",
      "Epoch 87/1300\n",
      "1099/1099 [==============================] - 0s 282us/step - loss: 0.4595 - acc: 0.7625\n",
      "Epoch 88/1300\n",
      "1099/1099 [==============================] - 0s 251us/step - loss: 0.4570 - acc: 0.7652\n",
      "Epoch 89/1300\n",
      "1099/1099 [==============================] - 0s 274us/step - loss: 0.4581 - acc: 0.7534\n",
      "Epoch 90/1300\n",
      "1099/1099 [==============================] - 0s 243us/step - loss: 0.4574 - acc: 0.7662\n",
      "Epoch 91/1300\n",
      "1099/1099 [==============================] - 0s 264us/step - loss: 0.4615 - acc: 0.7598\n",
      "Epoch 92/1300\n",
      "1099/1099 [==============================] - 0s 326us/step - loss: 0.4552 - acc: 0.7662\n",
      "Epoch 93/1300\n",
      "1099/1099 [==============================] - 0s 296us/step - loss: 0.4547 - acc: 0.7725\n",
      "Epoch 94/1300\n",
      "1099/1099 [==============================] - 0s 268us/step - loss: 0.4553 - acc: 0.7652\n",
      "Epoch 95/1300\n",
      "1099/1099 [==============================] - 0s 284us/step - loss: 0.4555 - acc: 0.7662\n",
      "Epoch 96/1300\n",
      "1099/1099 [==============================] - 0s 245us/step - loss: 0.4566 - acc: 0.7607\n",
      "Epoch 97/1300\n",
      "1099/1099 [==============================] - 0s 269us/step - loss: 0.4573 - acc: 0.7753\n",
      "Epoch 98/1300\n",
      "1099/1099 [==============================] - 0s 316us/step - loss: 0.4560 - acc: 0.7607\n",
      "Epoch 99/1300\n",
      "1099/1099 [==============================] - 0s 341us/step - loss: 0.4548 - acc: 0.7625\n",
      "Epoch 100/1300\n",
      "1099/1099 [==============================] - 0s 288us/step - loss: 0.4549 - acc: 0.7625\n",
      "Epoch 101/1300\n",
      "1099/1099 [==============================] - 0s 282us/step - loss: 0.4522 - acc: 0.7662\n",
      "Epoch 102/1300\n",
      "1099/1099 [==============================] - 0s 280us/step - loss: 0.4537 - acc: 0.7671\n",
      "Epoch 103/1300\n",
      "1099/1099 [==============================] - 0s 282us/step - loss: 0.4522 - acc: 0.7662\n",
      "Epoch 104/1300\n",
      "1099/1099 [==============================] - 0s 289us/step - loss: 0.4520 - acc: 0.7643\n",
      "Epoch 105/1300\n",
      "1099/1099 [==============================] - 0s 273us/step - loss: 0.4515 - acc: 0.7716\n",
      "Epoch 106/1300\n",
      "1099/1099 [==============================] - 0s 269us/step - loss: 0.4534 - acc: 0.7607\n",
      "Epoch 107/1300\n",
      "1099/1099 [==============================] - 0s 262us/step - loss: 0.4500 - acc: 0.7689\n",
      "Epoch 108/1300\n",
      "1099/1099 [==============================] - 0s 263us/step - loss: 0.4524 - acc: 0.7789\n",
      "Epoch 109/1300\n",
      "1099/1099 [==============================] - 0s 283us/step - loss: 0.4534 - acc: 0.7707\n",
      "Epoch 110/1300\n",
      "1099/1099 [==============================] - 0s 272us/step - loss: 0.4518 - acc: 0.7634\n",
      "Epoch 111/1300\n",
      "1099/1099 [==============================] - 0s 286us/step - loss: 0.4524 - acc: 0.7716\n",
      "Epoch 112/1300\n",
      "1099/1099 [==============================] - 0s 296us/step - loss: 0.4518 - acc: 0.7662\n",
      "Epoch 113/1300\n",
      "1099/1099 [==============================] - 0s 292us/step - loss: 0.4504 - acc: 0.7652\n",
      "Epoch 114/1300\n",
      "1099/1099 [==============================] - 0s 277us/step - loss: 0.4495 - acc: 0.7643\n",
      "Epoch 115/1300\n",
      "1099/1099 [==============================] - 0s 275us/step - loss: 0.4500 - acc: 0.7671\n",
      "Epoch 116/1300\n",
      "1099/1099 [==============================] - 0s 286us/step - loss: 0.4531 - acc: 0.7652\n",
      "Epoch 117/1300\n",
      "1099/1099 [==============================] - 0s 289us/step - loss: 0.4489 - acc: 0.7734\n",
      "Epoch 118/1300\n",
      "1099/1099 [==============================] - 0s 271us/step - loss: 0.4509 - acc: 0.7734\n",
      "Epoch 119/1300\n",
      "1099/1099 [==============================] - 0s 270us/step - loss: 0.4496 - acc: 0.7680\n",
      "Epoch 120/1300\n",
      "1099/1099 [==============================] - 0s 292us/step - loss: 0.4479 - acc: 0.7780\n",
      "Epoch 121/1300\n",
      "1099/1099 [==============================] - 0s 290us/step - loss: 0.4476 - acc: 0.7698\n",
      "Epoch 122/1300\n",
      "1099/1099 [==============================] - 0s 273us/step - loss: 0.4473 - acc: 0.7707\n",
      "Epoch 123/1300\n",
      "1099/1099 [==============================] - 0s 294us/step - loss: 0.4486 - acc: 0.7662\n",
      "Epoch 124/1300\n",
      "1099/1099 [==============================] - 0s 346us/step - loss: 0.4467 - acc: 0.7634\n",
      "Epoch 125/1300\n",
      "1099/1099 [==============================] - 0s 391us/step - loss: 0.4467 - acc: 0.7762\n",
      "Epoch 126/1300\n",
      "1099/1099 [==============================] - 0s 342us/step - loss: 0.4456 - acc: 0.7680\n",
      "Epoch 127/1300\n",
      "1099/1099 [==============================] - 0s 337us/step - loss: 0.4488 - acc: 0.7689\n",
      "Epoch 128/1300\n",
      "1099/1099 [==============================] - 0s 419us/step - loss: 0.4462 - acc: 0.7689\n",
      "Epoch 129/1300\n",
      "1099/1099 [==============================] - 0s 338us/step - loss: 0.4488 - acc: 0.7707\n",
      "Epoch 130/1300\n",
      "1099/1099 [==============================] - 0s 296us/step - loss: 0.4459 - acc: 0.7725\n",
      "Epoch 131/1300\n",
      "1099/1099 [==============================] - 0s 266us/step - loss: 0.4452 - acc: 0.7634\n",
      "Epoch 132/1300\n",
      "1099/1099 [==============================] - 0s 277us/step - loss: 0.4445 - acc: 0.7725\n",
      "Epoch 133/1300\n",
      "1099/1099 [==============================] - 0s 221us/step - loss: 0.4474 - acc: 0.7716\n",
      "Epoch 134/1300\n",
      "1099/1099 [==============================] - 0s 238us/step - loss: 0.4482 - acc: 0.7680\n",
      "Epoch 135/1300\n",
      "1099/1099 [==============================] - 0s 228us/step - loss: 0.4441 - acc: 0.7698\n",
      "Epoch 136/1300\n",
      "1099/1099 [==============================] - 0s 240us/step - loss: 0.4442 - acc: 0.7762\n",
      "Epoch 137/1300\n",
      "1099/1099 [==============================] - 0s 220us/step - loss: 0.4456 - acc: 0.7771\n",
      "Epoch 138/1300\n",
      "1099/1099 [==============================] - 0s 314us/step - loss: 0.4457 - acc: 0.7698\n",
      "Epoch 139/1300\n",
      "1099/1099 [==============================] - 0s 230us/step - loss: 0.4420 - acc: 0.7780\n",
      "Epoch 140/1300\n",
      "1099/1099 [==============================] - 0s 315us/step - loss: 0.4429 - acc: 0.7689\n",
      "Epoch 141/1300\n",
      "1099/1099 [==============================] - 0s 273us/step - loss: 0.4433 - acc: 0.7734\n",
      "Epoch 142/1300\n",
      "1099/1099 [==============================] - 0s 304us/step - loss: 0.4441 - acc: 0.7725\n",
      "Epoch 143/1300\n",
      "1099/1099 [==============================] - 0s 218us/step - loss: 0.4415 - acc: 0.7680\n",
      "Epoch 144/1300\n",
      "1099/1099 [==============================] - 0s 205us/step - loss: 0.4398 - acc: 0.7798\n",
      "Epoch 145/1300\n",
      "1099/1099 [==============================] - 0s 231us/step - loss: 0.4423 - acc: 0.7843\n",
      "Epoch 146/1300\n",
      "1099/1099 [==============================] - 0s 236us/step - loss: 0.4398 - acc: 0.7780\n",
      "Epoch 147/1300\n",
      "1099/1099 [==============================] - 0s 221us/step - loss: 0.4409 - acc: 0.7707\n",
      "Epoch 148/1300\n",
      "1099/1099 [==============================] - 0s 191us/step - loss: 0.4440 - acc: 0.7671\n",
      "Epoch 149/1300\n",
      "1099/1099 [==============================] - 0s 217us/step - loss: 0.4407 - acc: 0.7716\n",
      "Epoch 150/1300\n",
      "1099/1099 [==============================] - 0s 215us/step - loss: 0.4390 - acc: 0.7807\n",
      "Epoch 151/1300\n",
      "1099/1099 [==============================] - 0s 222us/step - loss: 0.4407 - acc: 0.7680\n",
      "Epoch 152/1300\n",
      "1099/1099 [==============================] - 0s 207us/step - loss: 0.4410 - acc: 0.7671\n",
      "Epoch 153/1300\n",
      "1099/1099 [==============================] - 0s 209us/step - loss: 0.4395 - acc: 0.7643\n",
      "Epoch 154/1300\n",
      "1099/1099 [==============================] - 0s 216us/step - loss: 0.4417 - acc: 0.7680\n",
      "Epoch 155/1300\n",
      "1099/1099 [==============================] - 0s 212us/step - loss: 0.4395 - acc: 0.7725\n",
      "Epoch 156/1300\n",
      "1099/1099 [==============================] - 0s 217us/step - loss: 0.4393 - acc: 0.7698\n",
      "Epoch 157/1300\n",
      "1099/1099 [==============================] - 0s 216us/step - loss: 0.4421 - acc: 0.7716\n",
      "Epoch 158/1300\n",
      "1099/1099 [==============================] - 0s 213us/step - loss: 0.4427 - acc: 0.7780\n",
      "Epoch 159/1300\n",
      "1099/1099 [==============================] - 0s 206us/step - loss: 0.4399 - acc: 0.7689\n",
      "Epoch 160/1300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1099/1099 [==============================] - 0s 222us/step - loss: 0.4375 - acc: 0.7716\n",
      "Epoch 161/1300\n",
      "1099/1099 [==============================] - 0s 214us/step - loss: 0.4402 - acc: 0.7671\n",
      "Epoch 162/1300\n",
      "1099/1099 [==============================] - 0s 212us/step - loss: 0.4377 - acc: 0.7725\n",
      "Epoch 163/1300\n",
      "1099/1099 [==============================] - 0s 212us/step - loss: 0.4392 - acc: 0.7707\n",
      "Epoch 164/1300\n",
      "1099/1099 [==============================] - 0s 215us/step - loss: 0.4371 - acc: 0.7743\n",
      "Epoch 165/1300\n",
      "1099/1099 [==============================] - 0s 261us/step - loss: 0.4359 - acc: 0.7789\n",
      "Epoch 166/1300\n",
      "1099/1099 [==============================] - 0s 255us/step - loss: 0.4371 - acc: 0.7707\n",
      "Epoch 167/1300\n",
      "1099/1099 [==============================] - 0s 285us/step - loss: 0.4374 - acc: 0.7753\n",
      "Epoch 168/1300\n",
      "1099/1099 [==============================] - 0s 229us/step - loss: 0.4394 - acc: 0.7689\n",
      "Epoch 169/1300\n",
      "1099/1099 [==============================] - 0s 241us/step - loss: 0.4385 - acc: 0.7807\n",
      "Epoch 170/1300\n",
      "1099/1099 [==============================] - 0s 271us/step - loss: 0.4374 - acc: 0.7716\n",
      "Epoch 171/1300\n",
      "1099/1099 [==============================] - 0s 233us/step - loss: 0.4361 - acc: 0.7753\n",
      "Epoch 172/1300\n",
      "1099/1099 [==============================] - 0s 256us/step - loss: 0.4372 - acc: 0.7725\n",
      "Epoch 173/1300\n",
      "1099/1099 [==============================] - 0s 261us/step - loss: 0.4351 - acc: 0.7780\n",
      "Epoch 174/1300\n",
      "1099/1099 [==============================] - 0s 255us/step - loss: 0.4345 - acc: 0.7634\n",
      "Epoch 175/1300\n",
      "1099/1099 [==============================] - 0s 230us/step - loss: 0.4381 - acc: 0.7753\n",
      "Epoch 176/1300\n",
      "1099/1099 [==============================] - 0s 246us/step - loss: 0.4332 - acc: 0.7698\n",
      "Epoch 177/1300\n",
      "1099/1099 [==============================] - 0s 218us/step - loss: 0.4361 - acc: 0.7680\n",
      "Epoch 178/1300\n",
      "1099/1099 [==============================] - 0s 210us/step - loss: 0.4333 - acc: 0.7762\n",
      "Epoch 179/1300\n",
      "1099/1099 [==============================] - 0s 211us/step - loss: 0.4357 - acc: 0.7771\n",
      "Epoch 180/1300\n",
      "1099/1099 [==============================] - 0s 222us/step - loss: 0.4318 - acc: 0.7780\n",
      "Epoch 181/1300\n",
      "1099/1099 [==============================] - 0s 209us/step - loss: 0.4362 - acc: 0.7698\n",
      "Epoch 182/1300\n",
      "1099/1099 [==============================] - 0s 228us/step - loss: 0.4325 - acc: 0.7780\n",
      "Epoch 183/1300\n",
      "1099/1099 [==============================] - 0s 207us/step - loss: 0.4320 - acc: 0.7734\n",
      "Epoch 184/1300\n",
      "1099/1099 [==============================] - 0s 217us/step - loss: 0.4320 - acc: 0.7734\n",
      "Epoch 185/1300\n",
      "1099/1099 [==============================] - 0s 223us/step - loss: 0.4317 - acc: 0.7798\n",
      "Epoch 186/1300\n",
      "1099/1099 [==============================] - 0s 218us/step - loss: 0.4358 - acc: 0.7707\n",
      "Epoch 187/1300\n",
      "1099/1099 [==============================] - 0s 213us/step - loss: 0.4285 - acc: 0.7816\n",
      "Epoch 188/1300\n",
      "1099/1099 [==============================] - 0s 213us/step - loss: 0.4343 - acc: 0.7753\n",
      "Epoch 189/1300\n",
      "1099/1099 [==============================] - 0s 204us/step - loss: 0.4319 - acc: 0.7789\n",
      "Epoch 190/1300\n",
      "1099/1099 [==============================] - 0s 226us/step - loss: 0.4315 - acc: 0.7698\n",
      "Epoch 191/1300\n",
      "1099/1099 [==============================] - 0s 222us/step - loss: 0.4346 - acc: 0.7725\n",
      "Epoch 192/1300\n",
      "1099/1099 [==============================] - 0s 217us/step - loss: 0.4289 - acc: 0.7716\n",
      "Epoch 193/1300\n",
      "1099/1099 [==============================] - 0s 203us/step - loss: 0.4286 - acc: 0.7762\n",
      "Epoch 194/1300\n",
      "1099/1099 [==============================] - 0s 201us/step - loss: 0.4327 - acc: 0.7662\n",
      "Epoch 195/1300\n",
      "1099/1099 [==============================] - 0s 220us/step - loss: 0.4306 - acc: 0.7743\n",
      "Epoch 196/1300\n",
      "1099/1099 [==============================] - 0s 217us/step - loss: 0.4277 - acc: 0.7753\n",
      "Epoch 197/1300\n",
      "1099/1099 [==============================] - 0s 213us/step - loss: 0.4283 - acc: 0.7725\n",
      "Epoch 198/1300\n",
      "1099/1099 [==============================] - 0s 217us/step - loss: 0.4267 - acc: 0.7707\n",
      "Epoch 199/1300\n",
      "1099/1099 [==============================] - 0s 215us/step - loss: 0.4305 - acc: 0.7743\n",
      "Epoch 200/1300\n",
      "1099/1099 [==============================] - 0s 215us/step - loss: 0.4262 - acc: 0.7780\n",
      "Epoch 201/1300\n",
      "1099/1099 [==============================] - 0s 210us/step - loss: 0.4298 - acc: 0.7743\n",
      "Epoch 202/1300\n",
      "1099/1099 [==============================] - 0s 210us/step - loss: 0.4270 - acc: 0.7771\n",
      "Epoch 203/1300\n",
      "1099/1099 [==============================] - 0s 210us/step - loss: 0.4292 - acc: 0.7771\n",
      "Epoch 204/1300\n",
      "1099/1099 [==============================] - 0s 209us/step - loss: 0.4234 - acc: 0.7816\n",
      "Epoch 205/1300\n",
      "1099/1099 [==============================] - 0s 217us/step - loss: 0.4296 - acc: 0.7743\n",
      "Epoch 206/1300\n",
      "1099/1099 [==============================] - 0s 225us/step - loss: 0.4283 - acc: 0.7743\n",
      "Epoch 207/1300\n",
      "1099/1099 [==============================] - 0s 209us/step - loss: 0.4270 - acc: 0.7753\n",
      "Epoch 208/1300\n",
      "1099/1099 [==============================] - 0s 209us/step - loss: 0.4291 - acc: 0.7753\n",
      "Epoch 209/1300\n",
      "1099/1099 [==============================] - 0s 213us/step - loss: 0.4235 - acc: 0.7853\n",
      "Epoch 210/1300\n",
      "1099/1099 [==============================] - 0s 217us/step - loss: 0.4239 - acc: 0.7798\n",
      "Epoch 211/1300\n",
      "1099/1099 [==============================] - 0s 210us/step - loss: 0.4268 - acc: 0.7716\n",
      "Epoch 212/1300\n",
      "1099/1099 [==============================] - 0s 212us/step - loss: 0.4274 - acc: 0.7753\n",
      "Epoch 213/1300\n",
      "1099/1099 [==============================] - 0s 200us/step - loss: 0.4218 - acc: 0.7689\n",
      "Epoch 214/1300\n",
      "1099/1099 [==============================] - 0s 210us/step - loss: 0.4232 - acc: 0.7853\n",
      "Epoch 215/1300\n",
      "1099/1099 [==============================] - 0s 212us/step - loss: 0.4237 - acc: 0.7707\n",
      "Epoch 216/1300\n",
      "1099/1099 [==============================] - 0s 219us/step - loss: 0.4260 - acc: 0.7734\n",
      "Epoch 217/1300\n",
      "1099/1099 [==============================] - 0s 221us/step - loss: 0.4233 - acc: 0.7834\n",
      "Epoch 218/1300\n",
      "1099/1099 [==============================] - 0s 220us/step - loss: 0.4213 - acc: 0.7734\n",
      "Epoch 219/1300\n",
      "1099/1099 [==============================] - 0s 208us/step - loss: 0.4239 - acc: 0.7825\n",
      "Epoch 220/1300\n",
      "1099/1099 [==============================] - 0s 193us/step - loss: 0.4231 - acc: 0.7771\n",
      "Epoch 221/1300\n",
      "1099/1099 [==============================] - 0s 205us/step - loss: 0.4210 - acc: 0.7843\n",
      "Epoch 222/1300\n",
      "1099/1099 [==============================] - 0s 208us/step - loss: 0.4251 - acc: 0.7825\n",
      "Epoch 223/1300\n",
      "1099/1099 [==============================] - 0s 209us/step - loss: 0.4203 - acc: 0.7925\n",
      "Epoch 224/1300\n",
      "1099/1099 [==============================] - 0s 207us/step - loss: 0.4208 - acc: 0.7753\n",
      "Epoch 225/1300\n",
      "1099/1099 [==============================] - 0s 213us/step - loss: 0.4221 - acc: 0.7707\n",
      "Epoch 226/1300\n",
      "1099/1099 [==============================] - 0s 213us/step - loss: 0.4212 - acc: 0.7753\n",
      "Epoch 227/1300\n",
      "1099/1099 [==============================] - 0s 215us/step - loss: 0.4221 - acc: 0.7816\n",
      "Epoch 228/1300\n",
      "1099/1099 [==============================] - 0s 227us/step - loss: 0.4185 - acc: 0.7789\n",
      "Epoch 229/1300\n",
      "1099/1099 [==============================] - 0s 274us/step - loss: 0.4173 - acc: 0.7907\n",
      "Epoch 230/1300\n",
      "1099/1099 [==============================] - 0s 214us/step - loss: 0.4193 - acc: 0.7780\n",
      "Epoch 231/1300\n",
      "1099/1099 [==============================] - 0s 216us/step - loss: 0.4205 - acc: 0.7753\n",
      "Epoch 232/1300\n",
      "1099/1099 [==============================] - 0s 213us/step - loss: 0.4181 - acc: 0.7907\n",
      "Epoch 233/1300\n",
      "1099/1099 [==============================] - 0s 218us/step - loss: 0.4179 - acc: 0.7889\n",
      "Epoch 234/1300\n",
      "1099/1099 [==============================] - 0s 211us/step - loss: 0.4164 - acc: 0.7789\n",
      "Epoch 235/1300\n",
      "1099/1099 [==============================] - 0s 210us/step - loss: 0.4196 - acc: 0.7862\n",
      "Epoch 236/1300\n",
      "1099/1099 [==============================] - 0s 218us/step - loss: 0.4186 - acc: 0.7798\n",
      "Epoch 237/1300\n",
      "1099/1099 [==============================] - 0s 230us/step - loss: 0.4151 - acc: 0.7816\n",
      "Epoch 238/1300\n",
      "1099/1099 [==============================] - 0s 218us/step - loss: 0.4183 - acc: 0.7762\n",
      "Epoch 239/1300\n",
      "1099/1099 [==============================] - 0s 193us/step - loss: 0.4136 - acc: 0.7889\n",
      "Epoch 240/1300\n",
      "1099/1099 [==============================] - 0s 215us/step - loss: 0.4183 - acc: 0.7853\n",
      "Epoch 241/1300\n",
      "1099/1099 [==============================] - 0s 219us/step - loss: 0.4187 - acc: 0.7753\n",
      "Epoch 242/1300\n",
      "1099/1099 [==============================] - 0s 211us/step - loss: 0.4173 - acc: 0.7798\n",
      "Epoch 243/1300\n",
      "1099/1099 [==============================] - 0s 192us/step - loss: 0.4174 - acc: 0.7798\n",
      "Epoch 244/1300\n",
      "1099/1099 [==============================] - 0s 204us/step - loss: 0.4134 - acc: 0.7871\n",
      "Epoch 245/1300\n",
      "1099/1099 [==============================] - 0s 209us/step - loss: 0.4160 - acc: 0.7880\n",
      "Epoch 246/1300\n",
      "1099/1099 [==============================] - 0s 214us/step - loss: 0.4125 - acc: 0.7780\n",
      "Epoch 247/1300\n",
      "1099/1099 [==============================] - 0s 220us/step - loss: 0.4163 - acc: 0.7853\n",
      "Epoch 248/1300\n",
      "1099/1099 [==============================] - 0s 220us/step - loss: 0.4162 - acc: 0.7834\n",
      "Epoch 249/1300\n",
      "1099/1099 [==============================] - 0s 205us/step - loss: 0.4137 - acc: 0.7789\n",
      "Epoch 250/1300\n",
      "1099/1099 [==============================] - 0s 202us/step - loss: 0.4141 - acc: 0.7762\n",
      "Epoch 251/1300\n",
      "1099/1099 [==============================] - 0s 211us/step - loss: 0.4134 - acc: 0.7807\n",
      "Epoch 252/1300\n",
      "1099/1099 [==============================] - 0s 218us/step - loss: 0.4114 - acc: 0.7916\n",
      "Epoch 253/1300\n",
      "1099/1099 [==============================] - 0s 205us/step - loss: 0.4142 - acc: 0.7816\n",
      "Epoch 254/1300\n",
      "1099/1099 [==============================] - 0s 212us/step - loss: 0.4138 - acc: 0.7853\n",
      "Epoch 255/1300\n",
      "1099/1099 [==============================] - 0s 205us/step - loss: 0.4100 - acc: 0.7862\n",
      "Epoch 256/1300\n",
      "1099/1099 [==============================] - 0s 210us/step - loss: 0.4154 - acc: 0.7816\n",
      "Epoch 257/1300\n",
      "1099/1099 [==============================] - 0s 205us/step - loss: 0.4120 - acc: 0.7816\n",
      "Epoch 258/1300\n",
      "1099/1099 [==============================] - 0s 215us/step - loss: 0.4142 - acc: 0.7871\n",
      "Epoch 259/1300\n",
      "1099/1099 [==============================] - 0s 199us/step - loss: 0.4105 - acc: 0.7871\n",
      "Epoch 260/1300\n",
      "1099/1099 [==============================] - 0s 221us/step - loss: 0.4087 - acc: 0.7862\n",
      "Epoch 261/1300\n",
      "1099/1099 [==============================] - 0s 198us/step - loss: 0.4111 - acc: 0.7934\n",
      "Epoch 262/1300\n",
      "1099/1099 [==============================] - 0s 206us/step - loss: 0.4092 - acc: 0.7825\n",
      "Epoch 263/1300\n",
      "1099/1099 [==============================] - 0s 214us/step - loss: 0.4068 - acc: 0.7853\n",
      "Epoch 264/1300\n",
      "1099/1099 [==============================] - 0s 204us/step - loss: 0.4143 - acc: 0.7862\n",
      "Epoch 265/1300\n",
      "1099/1099 [==============================] - 0s 250us/step - loss: 0.4091 - acc: 0.7871\n",
      "Epoch 266/1300\n",
      "1099/1099 [==============================] - 0s 208us/step - loss: 0.4090 - acc: 0.7907\n",
      "Epoch 267/1300\n",
      "1099/1099 [==============================] - 0s 208us/step - loss: 0.4075 - acc: 0.7853\n",
      "Epoch 268/1300\n",
      "1099/1099 [==============================] - 0s 209us/step - loss: 0.4060 - acc: 0.7980\n",
      "Epoch 269/1300\n",
      "1099/1099 [==============================] - 0s 202us/step - loss: 0.4082 - acc: 0.7825\n",
      "Epoch 270/1300\n",
      "1099/1099 [==============================] - 0s 219us/step - loss: 0.4070 - acc: 0.7898\n",
      "Epoch 271/1300\n",
      "1099/1099 [==============================] - 0s 218us/step - loss: 0.4080 - acc: 0.7889\n",
      "Epoch 272/1300\n",
      "1099/1099 [==============================] - 0s 208us/step - loss: 0.4043 - acc: 0.7862\n",
      "Epoch 273/1300\n",
      "1099/1099 [==============================] - 0s 195us/step - loss: 0.4079 - acc: 0.7753\n",
      "Epoch 274/1300\n",
      "1099/1099 [==============================] - 0s 213us/step - loss: 0.4100 - acc: 0.7889\n",
      "Epoch 275/1300\n",
      "1099/1099 [==============================] - 0s 213us/step - loss: 0.4027 - acc: 0.7944\n",
      "Epoch 276/1300\n",
      "1099/1099 [==============================] - 0s 234us/step - loss: 0.4074 - acc: 0.7907\n",
      "Epoch 277/1300\n",
      "1099/1099 [==============================] - 0s 223us/step - loss: 0.4064 - acc: 0.7925\n",
      "Epoch 278/1300\n",
      "1099/1099 [==============================] - 0s 190us/step - loss: 0.4025 - acc: 0.7916\n",
      "Epoch 279/1300\n",
      "1099/1099 [==============================] - 0s 217us/step - loss: 0.4061 - acc: 0.7953\n",
      "Epoch 280/1300\n",
      "1099/1099 [==============================] - 0s 207us/step - loss: 0.4045 - acc: 0.7834\n",
      "Epoch 281/1300\n",
      "1099/1099 [==============================] - 0s 220us/step - loss: 0.4034 - acc: 0.7834\n",
      "Epoch 282/1300\n",
      "1099/1099 [==============================] - 0s 211us/step - loss: 0.4025 - acc: 0.7871\n",
      "Epoch 283/1300\n",
      "1099/1099 [==============================] - 0s 212us/step - loss: 0.4024 - acc: 0.7889\n",
      "Epoch 284/1300\n",
      "1099/1099 [==============================] - 0s 209us/step - loss: 0.4021 - acc: 0.7916\n",
      "Epoch 285/1300\n",
      "1099/1099 [==============================] - 0s 211us/step - loss: 0.4051 - acc: 0.7834\n",
      "Epoch 286/1300\n",
      "1099/1099 [==============================] - 0s 207us/step - loss: 0.4032 - acc: 0.7962\n",
      "Epoch 287/1300\n",
      "1099/1099 [==============================] - 0s 216us/step - loss: 0.3993 - acc: 0.7962\n",
      "Epoch 288/1300\n",
      "1099/1099 [==============================] - 0s 206us/step - loss: 0.4021 - acc: 0.7889\n",
      "Epoch 289/1300\n",
      "1099/1099 [==============================] - 0s 216us/step - loss: 0.4022 - acc: 0.7907\n",
      "Epoch 290/1300\n",
      "1099/1099 [==============================] - 0s 223us/step - loss: 0.4004 - acc: 0.7989\n",
      "Epoch 291/1300\n",
      "1099/1099 [==============================] - 0s 216us/step - loss: 0.4008 - acc: 0.7944\n",
      "Epoch 292/1300\n",
      "1099/1099 [==============================] - 0s 221us/step - loss: 0.3996 - acc: 0.7880\n",
      "Epoch 293/1300\n",
      "1099/1099 [==============================] - 0s 217us/step - loss: 0.3994 - acc: 0.7916\n",
      "Epoch 294/1300\n",
      "1099/1099 [==============================] - 0s 224us/step - loss: 0.3974 - acc: 0.8016\n",
      "Epoch 295/1300\n",
      "1099/1099 [==============================] - 0s 219us/step - loss: 0.3958 - acc: 0.7971\n",
      "Epoch 296/1300\n",
      "1099/1099 [==============================] - 0s 226us/step - loss: 0.3993 - acc: 0.7971\n",
      "Epoch 297/1300\n",
      "1099/1099 [==============================] - 0s 242us/step - loss: 0.3996 - acc: 0.8007\n",
      "Epoch 298/1300\n",
      "1099/1099 [==============================] - 0s 223us/step - loss: 0.3995 - acc: 0.7898\n",
      "Epoch 299/1300\n",
      "1099/1099 [==============================] - 0s 228us/step - loss: 0.3931 - acc: 0.8007\n",
      "Epoch 300/1300\n",
      "1099/1099 [==============================] - 0s 219us/step - loss: 0.3946 - acc: 0.7934\n",
      "Epoch 301/1300\n",
      "1099/1099 [==============================] - 0s 286us/step - loss: 0.3967 - acc: 0.7980\n",
      "Epoch 302/1300\n",
      "1099/1099 [==============================] - 0s 247us/step - loss: 0.4001 - acc: 0.8035\n",
      "Epoch 303/1300\n",
      "1099/1099 [==============================] - 0s 207us/step - loss: 0.4013 - acc: 0.7925\n",
      "Epoch 304/1300\n",
      "1099/1099 [==============================] - 0s 244us/step - loss: 0.3979 - acc: 0.7953\n",
      "Epoch 305/1300\n",
      "1099/1099 [==============================] - 0s 239us/step - loss: 0.3974 - acc: 0.7998\n",
      "Epoch 306/1300\n",
      "1099/1099 [==============================] - 0s 241us/step - loss: 0.3984 - acc: 0.7962\n",
      "Epoch 307/1300\n",
      "1099/1099 [==============================] - 0s 233us/step - loss: 0.3949 - acc: 0.8044\n",
      "Epoch 308/1300\n",
      "1099/1099 [==============================] - 0s 207us/step - loss: 0.3952 - acc: 0.8016\n",
      "Epoch 309/1300\n",
      "1099/1099 [==============================] - 0s 228us/step - loss: 0.3909 - acc: 0.7980\n",
      "Epoch 310/1300\n",
      "1099/1099 [==============================] - 0s 257us/step - loss: 0.3996 - acc: 0.8007\n",
      "Epoch 311/1300\n",
      "1099/1099 [==============================] - 0s 234us/step - loss: 0.3946 - acc: 0.7962\n",
      "Epoch 312/1300\n",
      "1099/1099 [==============================] - 0s 227us/step - loss: 0.3970 - acc: 0.7843\n",
      "Epoch 313/1300\n",
      "1099/1099 [==============================] - 0s 274us/step - loss: 0.3938 - acc: 0.8007\n",
      "Epoch 314/1300\n",
      "1099/1099 [==============================] - 0s 247us/step - loss: 0.3959 - acc: 0.7889\n",
      "Epoch 315/1300\n",
      "1099/1099 [==============================] - 0s 242us/step - loss: 0.3955 - acc: 0.7925\n",
      "Epoch 316/1300\n",
      "1099/1099 [==============================] - 0s 225us/step - loss: 0.3926 - acc: 0.7998\n",
      "Epoch 317/1300\n",
      "1099/1099 [==============================] - 0s 283us/step - loss: 0.3922 - acc: 0.7971\n",
      "Epoch 318/1300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1099/1099 [==============================] - 0s 282us/step - loss: 0.3933 - acc: 0.8071\n",
      "Epoch 319/1300\n",
      "1099/1099 [==============================] - 0s 284us/step - loss: 0.3934 - acc: 0.8053\n",
      "Epoch 320/1300\n",
      "1099/1099 [==============================] - 0s 240us/step - loss: 0.3951 - acc: 0.8025\n",
      "Epoch 321/1300\n",
      "1099/1099 [==============================] - 0s 281us/step - loss: 0.3925 - acc: 0.7998\n",
      "Epoch 322/1300\n",
      "1099/1099 [==============================] - 0s 267us/step - loss: 0.3911 - acc: 0.8116\n",
      "Epoch 323/1300\n",
      "1099/1099 [==============================] - 0s 261us/step - loss: 0.3944 - acc: 0.7962\n",
      "Epoch 324/1300\n",
      "1099/1099 [==============================] - 0s 250us/step - loss: 0.3909 - acc: 0.8025\n",
      "Epoch 325/1300\n",
      "1099/1099 [==============================] - 0s 293us/step - loss: 0.3916 - acc: 0.7907\n",
      "Epoch 326/1300\n",
      "1099/1099 [==============================] - 0s 377us/step - loss: 0.3896 - acc: 0.8035\n",
      "Epoch 327/1300\n",
      "1099/1099 [==============================] - 0s 263us/step - loss: 0.3909 - acc: 0.7971\n",
      "Epoch 328/1300\n",
      "1099/1099 [==============================] - 0s 258us/step - loss: 0.3933 - acc: 0.8089\n",
      "Epoch 329/1300\n",
      "1099/1099 [==============================] - 0s 273us/step - loss: 0.3873 - acc: 0.8062\n",
      "Epoch 330/1300\n",
      "1099/1099 [==============================] - 0s 268us/step - loss: 0.3932 - acc: 0.7971\n",
      "Epoch 331/1300\n",
      "1099/1099 [==============================] - 0s 236us/step - loss: 0.3929 - acc: 0.7889\n",
      "Epoch 332/1300\n",
      "1099/1099 [==============================] - 0s 250us/step - loss: 0.3893 - acc: 0.8007\n",
      "Epoch 333/1300\n",
      "1099/1099 [==============================] - 0s 241us/step - loss: 0.3884 - acc: 0.7998\n",
      "Epoch 334/1300\n",
      "1099/1099 [==============================] - 0s 278us/step - loss: 0.3876 - acc: 0.8007\n",
      "Epoch 335/1300\n",
      "1099/1099 [==============================] - 0s 238us/step - loss: 0.3905 - acc: 0.7980\n",
      "Epoch 336/1300\n",
      "1099/1099 [==============================] - 0s 245us/step - loss: 0.3879 - acc: 0.7971\n",
      "Epoch 337/1300\n",
      "1099/1099 [==============================] - 0s 254us/step - loss: 0.3901 - acc: 0.7980\n",
      "Epoch 338/1300\n",
      "1099/1099 [==============================] - 0s 294us/step - loss: 0.3896 - acc: 0.7916\n",
      "Epoch 339/1300\n",
      "1099/1099 [==============================] - 0s 248us/step - loss: 0.3907 - acc: 0.8007\n",
      "Epoch 340/1300\n",
      "1099/1099 [==============================] - 0s 238us/step - loss: 0.3894 - acc: 0.8053\n",
      "Epoch 341/1300\n",
      "1099/1099 [==============================] - 0s 264us/step - loss: 0.3883 - acc: 0.7907\n",
      "Epoch 342/1300\n",
      "1099/1099 [==============================] - 0s 252us/step - loss: 0.3866 - acc: 0.8098\n",
      "Epoch 343/1300\n",
      "1099/1099 [==============================] - 0s 300us/step - loss: 0.3857 - acc: 0.8044\n",
      "Epoch 344/1300\n",
      "1099/1099 [==============================] - 0s 325us/step - loss: 0.3844 - acc: 0.8035\n",
      "Epoch 345/1300\n",
      "1099/1099 [==============================] - 0s 325us/step - loss: 0.3856 - acc: 0.8062\n",
      "Epoch 346/1300\n",
      "1099/1099 [==============================] - 0s 291us/step - loss: 0.3871 - acc: 0.8098\n",
      "Epoch 347/1300\n",
      "1099/1099 [==============================] - 0s 286us/step - loss: 0.3837 - acc: 0.8044\n",
      "Epoch 348/1300\n",
      "1099/1099 [==============================] - 0s 340us/step - loss: 0.3832 - acc: 0.8016\n",
      "Epoch 349/1300\n",
      "1099/1099 [==============================] - 0s 317us/step - loss: 0.3835 - acc: 0.8016\n",
      "Epoch 350/1300\n",
      "1099/1099 [==============================] - 0s 283us/step - loss: 0.3867 - acc: 0.7953\n",
      "Epoch 351/1300\n",
      "1099/1099 [==============================] - 0s 220us/step - loss: 0.3858 - acc: 0.7989\n",
      "Epoch 352/1300\n",
      "1099/1099 [==============================] - 0s 225us/step - loss: 0.3873 - acc: 0.7934\n",
      "Epoch 353/1300\n",
      "1099/1099 [==============================] - 0s 233us/step - loss: 0.3869 - acc: 0.8071\n",
      "Epoch 354/1300\n",
      "1099/1099 [==============================] - 0s 228us/step - loss: 0.3860 - acc: 0.7962\n",
      "Epoch 355/1300\n",
      "1099/1099 [==============================] - 0s 262us/step - loss: 0.3825 - acc: 0.8080\n",
      "Epoch 356/1300\n",
      "1099/1099 [==============================] - 0s 229us/step - loss: 0.3833 - acc: 0.8007\n",
      "Epoch 357/1300\n",
      "1099/1099 [==============================] - 0s 216us/step - loss: 0.3838 - acc: 0.8007\n",
      "Epoch 358/1300\n",
      "1099/1099 [==============================] - 0s 226us/step - loss: 0.3896 - acc: 0.8098\n",
      "Epoch 359/1300\n",
      "1099/1099 [==============================] - 0s 253us/step - loss: 0.3852 - acc: 0.8071\n",
      "Epoch 360/1300\n",
      "1099/1099 [==============================] - 0s 218us/step - loss: 0.3841 - acc: 0.7980\n",
      "Epoch 361/1300\n",
      "1099/1099 [==============================] - 0s 217us/step - loss: 0.3835 - acc: 0.8071\n",
      "Epoch 362/1300\n",
      "1099/1099 [==============================] - 0s 331us/step - loss: 0.3814 - acc: 0.8035\n",
      "Epoch 363/1300\n",
      "1099/1099 [==============================] - 0s 249us/step - loss: 0.3831 - acc: 0.8035\n",
      "Epoch 364/1300\n",
      "1099/1099 [==============================] - 0s 245us/step - loss: 0.3806 - acc: 0.8025\n",
      "Epoch 365/1300\n",
      "1099/1099 [==============================] - 0s 248us/step - loss: 0.3785 - acc: 0.8107\n",
      "Epoch 366/1300\n",
      "1099/1099 [==============================] - 0s 341us/step - loss: 0.3835 - acc: 0.7944\n",
      "Epoch 367/1300\n",
      "1099/1099 [==============================] - 0s 296us/step - loss: 0.3825 - acc: 0.8007\n",
      "Epoch 368/1300\n",
      "1099/1099 [==============================] - 0s 275us/step - loss: 0.3817 - acc: 0.8089\n",
      "Epoch 369/1300\n",
      "1099/1099 [==============================] - 0s 231us/step - loss: 0.3843 - acc: 0.8025\n",
      "Epoch 370/1300\n",
      "1099/1099 [==============================] - 0s 298us/step - loss: 0.3796 - acc: 0.8080\n",
      "Epoch 371/1300\n",
      "1099/1099 [==============================] - 0s 221us/step - loss: 0.3795 - acc: 0.8016\n",
      "Epoch 372/1300\n",
      "1099/1099 [==============================] - 0s 277us/step - loss: 0.3842 - acc: 0.7971\n",
      "Epoch 373/1300\n",
      "1099/1099 [==============================] - 0s 285us/step - loss: 0.3817 - acc: 0.8044\n",
      "Epoch 374/1300\n",
      "1099/1099 [==============================] - 0s 346us/step - loss: 0.3786 - acc: 0.8107\n",
      "Epoch 375/1300\n",
      "1099/1099 [==============================] - 0s 313us/step - loss: 0.3796 - acc: 0.8098\n",
      "Epoch 376/1300\n",
      "1099/1099 [==============================] - 0s 289us/step - loss: 0.3818 - acc: 0.7989\n",
      "Epoch 377/1300\n",
      "1099/1099 [==============================] - 0s 349us/step - loss: 0.3735 - acc: 0.8098\n",
      "Epoch 378/1300\n",
      "1099/1099 [==============================] - 0s 310us/step - loss: 0.3783 - acc: 0.8080\n",
      "Epoch 379/1300\n",
      "1099/1099 [==============================] - 0s 254us/step - loss: 0.3781 - acc: 0.8080\n",
      "Epoch 380/1300\n",
      "1099/1099 [==============================] - 0s 252us/step - loss: 0.3789 - acc: 0.8016\n",
      "Epoch 381/1300\n",
      "1099/1099 [==============================] - 0s 191us/step - loss: 0.3782 - acc: 0.8080\n",
      "Epoch 382/1300\n",
      "1099/1099 [==============================] - 0s 351us/step - loss: 0.3767 - acc: 0.8126\n",
      "Epoch 383/1300\n",
      "1099/1099 [==============================] - 0s 317us/step - loss: 0.3804 - acc: 0.8035\n",
      "Epoch 384/1300\n",
      "1099/1099 [==============================] - 0s 240us/step - loss: 0.3756 - acc: 0.8135\n",
      "Epoch 385/1300\n",
      "1099/1099 [==============================] - 0s 239us/step - loss: 0.3771 - acc: 0.8053\n",
      "Epoch 386/1300\n",
      "1099/1099 [==============================] - 0s 228us/step - loss: 0.3778 - acc: 0.7998\n",
      "Epoch 387/1300\n",
      "1099/1099 [==============================] - 0s 222us/step - loss: 0.3732 - acc: 0.8144\n",
      "Epoch 388/1300\n",
      "1099/1099 [==============================] - 0s 210us/step - loss: 0.3726 - acc: 0.8162\n",
      "Epoch 389/1300\n",
      "1099/1099 [==============================] - 0s 213us/step - loss: 0.3768 - acc: 0.8153\n",
      "Epoch 390/1300\n",
      "1099/1099 [==============================] - 0s 194us/step - loss: 0.3754 - acc: 0.8035\n",
      "Epoch 391/1300\n",
      "1099/1099 [==============================] - 0s 235us/step - loss: 0.3750 - acc: 0.8116\n",
      "Epoch 392/1300\n",
      "1099/1099 [==============================] - 0s 241us/step - loss: 0.3782 - acc: 0.8080\n",
      "Epoch 393/1300\n",
      "1099/1099 [==============================] - 0s 240us/step - loss: 0.3777 - acc: 0.8144\n",
      "Epoch 394/1300\n",
      "1099/1099 [==============================] - 0s 245us/step - loss: 0.3716 - acc: 0.8153\n",
      "Epoch 395/1300\n",
      "1099/1099 [==============================] - 0s 211us/step - loss: 0.3730 - acc: 0.8080\n",
      "Epoch 396/1300\n",
      "1099/1099 [==============================] - 0s 283us/step - loss: 0.3739 - acc: 0.8098\n",
      "Epoch 397/1300\n",
      "1099/1099 [==============================] - 0s 322us/step - loss: 0.3762 - acc: 0.8016\n",
      "Epoch 398/1300\n",
      "1099/1099 [==============================] - 0s 292us/step - loss: 0.3675 - acc: 0.8162\n",
      "Epoch 399/1300\n",
      "1099/1099 [==============================] - 0s 211us/step - loss: 0.3728 - acc: 0.8171\n",
      "Epoch 400/1300\n",
      "1099/1099 [==============================] - 0s 214us/step - loss: 0.3713 - acc: 0.8071\n",
      "Epoch 401/1300\n",
      "1099/1099 [==============================] - 0s 236us/step - loss: 0.3743 - acc: 0.8198\n",
      "Epoch 402/1300\n",
      "1099/1099 [==============================] - 0s 446us/step - loss: 0.3684 - acc: 0.8080\n",
      "Epoch 403/1300\n",
      "1099/1099 [==============================] - 0s 389us/step - loss: 0.3747 - acc: 0.8062\n",
      "Epoch 404/1300\n",
      "1099/1099 [==============================] - 0s 337us/step - loss: 0.3716 - acc: 0.8198\n",
      "Epoch 405/1300\n",
      "1099/1099 [==============================] - 0s 287us/step - loss: 0.3725 - acc: 0.8171\n",
      "Epoch 406/1300\n",
      "1099/1099 [==============================] - 0s 284us/step - loss: 0.3730 - acc: 0.8107\n",
      "Epoch 407/1300\n",
      "1099/1099 [==============================] - 0s 276us/step - loss: 0.3743 - acc: 0.8116\n",
      "Epoch 408/1300\n",
      "1099/1099 [==============================] - 0s 312us/step - loss: 0.3720 - acc: 0.8126\n",
      "Epoch 409/1300\n",
      "1099/1099 [==============================] - 0s 276us/step - loss: 0.3692 - acc: 0.8053\n",
      "Epoch 410/1300\n",
      "1099/1099 [==============================] - 0s 257us/step - loss: 0.3703 - acc: 0.8135\n",
      "Epoch 411/1300\n",
      "1099/1099 [==============================] - 0s 241us/step - loss: 0.3711 - acc: 0.8126\n",
      "Epoch 412/1300\n",
      "1099/1099 [==============================] - 0s 357us/step - loss: 0.3692 - acc: 0.8126\n",
      "Epoch 413/1300\n",
      "1099/1099 [==============================] - 0s 353us/step - loss: 0.3679 - acc: 0.8153\n",
      "Epoch 414/1300\n",
      "1099/1099 [==============================] - 0s 272us/step - loss: 0.3726 - acc: 0.8062\n",
      "Epoch 415/1300\n",
      "1099/1099 [==============================] - 0s 283us/step - loss: 0.3656 - acc: 0.8207\n",
      "Epoch 416/1300\n",
      "1099/1099 [==============================] - 0s 258us/step - loss: 0.3704 - acc: 0.8171\n",
      "Epoch 417/1300\n",
      "1099/1099 [==============================] - 0s 320us/step - loss: 0.3705 - acc: 0.8071\n",
      "Epoch 418/1300\n",
      "1099/1099 [==============================] - 0s 391us/step - loss: 0.3673 - acc: 0.8116\n",
      "Epoch 419/1300\n",
      "1099/1099 [==============================] - 0s 319us/step - loss: 0.3734 - acc: 0.8207\n",
      "Epoch 420/1300\n",
      "1099/1099 [==============================] - 0s 270us/step - loss: 0.3706 - acc: 0.8135\n",
      "Epoch 421/1300\n",
      "1099/1099 [==============================] - 0s 277us/step - loss: 0.3666 - acc: 0.8144\n",
      "Epoch 422/1300\n",
      " 780/1099 [====================>.........] - ETA: 0s - loss: 0.3680 - acc: 0.8013"
     ]
    }
   ],
   "source": [
    "dataset=pd.read_csv(\"FeaturesDataset.csv\")\n",
    "x=dataset.iloc[:,0:12].values\n",
    "y=dataset.iloc[:,12].values\n",
    "labelencoder = LabelEncoder()\n",
    "y = labelencoder.fit_transform(y)\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scale = min_max_scaler.fit_transform(x)\n",
    "X_train, X_test, y_train, y_test=train_test_split(X_scale,y, test_size=0,random_state=None)\n",
    "model = Sequential([Dense(120, activation='relu', input_shape=(12,)),Dense(120, activation='relu'),Dense(1, activation='sigmoid'),])\n",
    "model.compile(optimizer='sgd',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.fit(X_train, y_train,batch_size=20, epochs=500)\n",
    "  # save the model to disk\n",
    "filename = 'ANN_model.sav'   \n",
    "joblib.dump(model, filename)\n",
    "        #y_pred_class = model.predict([mfcc])\n",
    "        #y_pred_class= [ 1 if y>=0.5 else 0 for y in y_pred_class]\n",
    "        #return y_pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
