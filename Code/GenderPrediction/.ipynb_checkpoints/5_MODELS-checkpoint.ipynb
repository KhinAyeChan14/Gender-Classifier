{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/khin/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing, neighbors\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import cross_val_score, cross_val_predict\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200, 1)\n",
      "['male']\n",
      "['female']\n"
     ]
    }
   ],
   "source": [
    "#producing x and y\n",
    "x= pd.read_csv('FeaturesDataset.csv',header=None,usecols=range(0,12) ,skiprows=1)\n",
    "x = np.array(x)\n",
    "#print(x[0])\n",
    "#print(x.shape)\n",
    "y= pd.read_csv('FeaturesDataset.csv',usecols=range(12,13),header=None,skiprows=1)\n",
    "\n",
    "y = np.array(y)\n",
    "print(y.shape)\n",
    "print(y[0])\n",
    "print(y[1199])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/khin/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/khin/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#lABEL ENCODING\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y)\n",
    "y = le.transform(y)\n",
    "#print(y[0])\n",
    "#print(y[900])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividing the data randomly into training and test set\n",
    "#x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.1,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'fillna'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-80f6acae6a2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#RadomForest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mx_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_ml\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConfusionMatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'fillna'"
     ]
    }
   ],
   "source": [
    "#Dividing the data randomly into training and test set\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.1,random_state=None)\n",
    "#RadomForest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from pandas_ml import ConfusionMatrix\n",
    "RF= RandomForestClassifier( )\n",
    "RF.fit(x_train, y_train)\n",
    "\n",
    "print('Trainig Accuracy for RandomForest :',RF.score(x_train,y_train))\n",
    "y_pred_class = RF.predict(x_test)\n",
    "print('Testing Accuracy for Random Forest:',metrics.accuracy_score(y_test, y_pred_class))\n",
    "#y_test=list(le.inverse_transform([y_test]))\n",
    "#print(y_test)\n",
    "#y_pred_class=list(le.inverse_transform([y_pred_class]))\n",
    "#print(y_pred_class)\n",
    "# save confusion matrix and slice into four pieces\n",
    "#print(metrics.confusion_matrix(y_test, y_pred_class))\n",
    "report=classification_report(y_test, y_pred_class,target_names=['female', 'male'])\n",
    "print(report)\n",
    "\n",
    "confusion = metrics.confusion_matrix(y_test, y_pred_class,)\n",
    "pd.crosstab(y_test, y_pred_class, rownames=['Actual'], colnames=['Predicted'],margins=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-ad2e547686bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Cross-validated scores for RF : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m   1579\u001b[0m                                               \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1580\u001b[0m                                               fit_params)\n\u001b[0;32m-> 1581\u001b[0;31m                       for train, test in cv)\n\u001b[0m\u001b[1;32m   1582\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, error_score)\u001b[0m\n\u001b[1;32m   1673\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1675\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1677\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \"\"\"\n\u001b[1;32m    246\u001b[0m         \u001b[0;31m# Validate or convert input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    451\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    452\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     42\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     43\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 44\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(RF, x, y, cv=10)\n",
    "print (\"Cross-validated scores for RF : \", scores)\n",
    "print(np.mean(scores))\n",
    "\n",
    "i=1\n",
    "kf = KFold(n_splits=10, random_state=0, shuffle=True)\n",
    "kf.get_n_splits(x)\n",
    "for train_index, test_index in kf.split(x):\n",
    "\n",
    "    X_train, X_test = x[train_index],x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    RF.fit(X_train, y_train)\n",
    "    y_pred_class = RF.predict(X_test)\n",
    "    print(\"Cross Validaton \", i ,\" : \",metrics.accuracy_score(y_test, y_pred_class))\n",
    "    i+=1\n",
    "    #print (confusion_matrix(y_test, RF.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-bd7493d9e678>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlogreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mlogreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Trainig Accuracy for Logistic Regression :'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlogreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype,\n\u001b[0;32m-> 1216\u001b[0;31m                          order=\"C\")\n\u001b[0m\u001b[1;32m   1217\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    571\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[1;32m    572\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[1;32m    574\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    451\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    452\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     42\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     43\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 44\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "#Dividing the data randomly into training and test set\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.1,random_state=None)\n",
    "#LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(x_train, y_train.ravel())\n",
    "\n",
    "print('Trainig Accuracy for Logistic Regression :',logreg.score(x_train,y_train))\n",
    "y_pred_class = logreg.predict(x_test)\n",
    "print('Testing Accuracy for Logistic Regression:',metrics.accuracy_score(y_test, y_pred_class))\n",
    "\n",
    "# save confusion matrix and slice into four pieces\n",
    "#print(metrics.confusion_matrix(y_test, y_pred_class))\n",
    "report=classification_report(y_test, y_pred_class,target_names=['female', 'male'])\n",
    "print(report)\n",
    "confusion = metrics.confusion_matrix(y_test, y_pred_class,)\n",
    "pd.crosstab(y_test, y_pred_class, rownames=['Actual'], colnames=['Predicted'],margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated scores LR :  [0.72972973 0.72972973 0.74774775 0.8        0.74545455 0.77272727\n",
      " 0.76146789 0.7706422  0.82568807 0.71559633]\n",
      "0.7598783520801868\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(logreg, x, y, cv=10)\n",
    "print (\"Cross-validated scores LR : \", scores)\n",
    "print(np.mean(scores))\n",
    "\n",
    "i=1\n",
    "kf = KFold(n_splits=10, random_state=0, shuffle=True)\n",
    "kf.get_n_splits(x)\n",
    "for train_index, test_index in kf.split(x):\n",
    "\n",
    "    X_train, X_test = x[train_index],x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    logreg.fit(X_train, y_train)\n",
    "    y_pred_class = logreg.predict(X_test)\n",
    "    #print(\"Cross Validaton \", i ,\" : \",metrics.accuracy_score(y_test, y_pred_class))\n",
    "    i+=1\n",
    "    #print (confusion_matrix(y_test, logreg.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainig Accuracy for Gaussian Naive Bayes : 0.7644084934277048\n",
      "Testing Accuracy for Gaussian Naives Bayes: 0.7454545454545455\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     female       0.75      0.77      0.76        57\n",
      "       male       0.75      0.72      0.73        53\n",
      "\n",
      "avg / total       0.75      0.75      0.75       110\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44</td>\n",
       "      <td>13</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>38</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>59</td>\n",
       "      <td>51</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0   1  All\n",
       "Actual                \n",
       "0          44  13   57\n",
       "1          15  38   53\n",
       "All        59  51  110"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dividing the data randomly into training and test set\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.1,random_state=None)\n",
    "#Gaussian Naive Bayes \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "GNB = GaussianNB()\n",
    "GNB.fit(x_train, y_train)\n",
    "print('Trainig Accuracy for Gaussian Naive Bayes :',GNB.score(x_train,y_train))\n",
    "y_pred_class = GNB.predict(x_test)\n",
    "print('Testing Accuracy for Gaussian Naives Bayes:',metrics.accuracy_score(y_test, y_pred_class))\n",
    "\n",
    "# save confusion matrix and slice into four pieces\n",
    "#print(metrics.confusion_matrix(y_test, y_pred_class))\n",
    "report=classification_report(y_test, y_pred_class,target_names=['female', 'male'])\n",
    "print(report)\n",
    "\n",
    "confusion = metrics.confusion_matrix(y_test, y_pred_class,)\n",
    "pd.crosstab(y_test, y_pred_class, rownames=['Actual'], colnames=['Predicted'],margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated scores GNB:  [0.74774775 0.72072072 0.77477477 0.76363636 0.77272727 0.77272727\n",
      " 0.74311927 0.75229358 0.77981651 0.73394495]\n",
      "0.7561508464260759\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(GNB, x, y, cv=10)\n",
    "print (\"Cross-validated scores GNB: \", scores)\n",
    "print(np.mean(scores))\n",
    "\n",
    "i=1\n",
    "kf = KFold(n_splits=10, random_state=0, shuffle=True)\n",
    "kf.get_n_splits(x)\n",
    "for train_index, test_index in kf.split(x):\n",
    "\n",
    "    X_train, X_test = x[train_index],x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    GNB.fit(X_train, y_train)\n",
    "    y_pred_class = GNB.predict(X_test)\n",
    "    #print(\"Cross Validaton \", i ,\" : \",metrics.accuracy_score(y_test, y_pred_class))\n",
    "    i+=1\n",
    "    #print (confusion_matrix(y_test,y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainig Accuracy for Support Vector Machine: 0.7623862487360971\n",
      "Testing Accuracy for Support Vector Machine: 0.7454545454545455\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     female       0.75      0.75      0.75        57\n",
      "       male       0.74      0.74      0.74        53\n",
      "\n",
      "avg / total       0.75      0.75      0.75       110\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43</td>\n",
       "      <td>14</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>39</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>57</td>\n",
       "      <td>53</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0   1  All\n",
       "Actual                \n",
       "0          43  14   57\n",
       "1          14  39   53\n",
       "All        57  53  110"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dividing the data randomly into training and test set\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.1,random_state=None)\n",
    "#SVM\n",
    "from sklearn import svm\n",
    "SVM= svm.SVC(kernel='linear') # Linear Kernel\n",
    "SVM.fit(x_train, y_train)\n",
    "print('Trainig Accuracy for Support Vector Machine:',SVM.score(x_train,y_train))\n",
    "y_pred_class = SVM.predict(x_test)\n",
    "print('Testing Accuracy for Support Vector Machine:',metrics.accuracy_score(y_test, y_pred_class))\n",
    "\n",
    "# save confusion matrix and slice into four pieces\n",
    "#print(metrics.confusion_matrix(y_test, y_pred_class))\n",
    "report=classification_report(y_test, y_pred_class,target_names=['female', 'male'])\n",
    "print(report)\n",
    "\n",
    "confusion = metrics.confusion_matrix(y_test, y_pred_class,)\n",
    "pd.crosstab(y_test, y_pred_class, rownames=['Actual'], colnames=['Predicted'],margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated scores SVM :  [0.75675676 0.72072072 0.73873874 0.8        0.75454545 0.76363636\n",
      " 0.75229358 0.76146789 0.81651376 0.74311927]\n",
      "0.7607792529810878\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(SVM, x, y, cv=10)\n",
    "print (\"Cross-validated scores SVM : \", scores)\n",
    "print(np.mean(scores))\n",
    "\n",
    "i=1\n",
    "kf = KFold(n_splits=10, random_state=0, shuffle=True)\n",
    "kf.get_n_splits(x)\n",
    "for train_index, test_index in kf.split(x):\n",
    "\n",
    "    X_train, X_test = x[train_index],x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    SVM.fit(X_train, y_train)\n",
    "    y_pred_class = SVM.predict(X_test)\n",
    "    #print(\"Cross Validaton \", i ,\" : \",metrics.accuracy_score(y_test, y_pred_class))\n",
    "    i+=1\n",
    "    #print (confusion_matrix(y_test, SVM.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import History\n",
    "from keras.utils import plot_model\n",
    "from keras.optimizers import SGD\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from scipy.io import wavfile\n",
    "from ipynb.fs.full.MFCC import *\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "from sklearn.externals import joblib\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.02000011   0.11503767 -11.11989863  -0.20737452  23.3575892\n",
      "  -4.75888206 -28.53938623   1.80523333   5.6716495   12.88089461\n",
      " -27.79506481   6.3313693 ]\n",
      "[0.92364985 0.60465404 0.52855164 0.52910986 0.71056307 0.56734856\n",
      " 0.37139865 0.52043631 0.64151623 0.68662052 0.19102176 0.67156364]\n",
      "Epoch 1/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.6946 - acc: 0.5116\n",
      "Epoch 2/500\n",
      "989/989 [==============================] - 1s 695us/step - loss: 0.6893 - acc: 0.5784\n",
      "Epoch 3/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.6845 - acc: 0.6309\n",
      "Epoch 4/500\n",
      "989/989 [==============================] - 1s 847us/step - loss: 0.6800 - acc: 0.6552\n",
      "Epoch 5/500\n",
      "989/989 [==============================] - 1s 650us/step - loss: 0.6757 - acc: 0.6704\n",
      "Epoch 6/500\n",
      "989/989 [==============================] - 1s 942us/step - loss: 0.6707 - acc: 0.6835\n",
      "Epoch 7/500\n",
      "989/989 [==============================] - 1s 805us/step - loss: 0.6663 - acc: 0.7037\n",
      "Epoch 8/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.6614 - acc: 0.6936\n",
      "Epoch 9/500\n",
      "989/989 [==============================] - 1s 806us/step - loss: 0.6556 - acc: 0.7037\n",
      "Epoch 10/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.6506 - acc: 0.7048\n",
      "Epoch 11/500\n",
      "989/989 [==============================] - 1s 901us/step - loss: 0.6446 - acc: 0.7098\n",
      "Epoch 12/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.6379 - acc: 0.7108\n",
      "Epoch 13/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.6309 - acc: 0.7260\n",
      "Epoch 14/500\n",
      "989/989 [==============================] - 1s 679us/step - loss: 0.6227 - acc: 0.7341\n",
      "Epoch 15/500\n",
      "989/989 [==============================] - 1s 958us/step - loss: 0.6151 - acc: 0.7310\n",
      "Epoch 16/500\n",
      "989/989 [==============================] - 1s 650us/step - loss: 0.6069 - acc: 0.7250\n",
      "Epoch 17/500\n",
      "989/989 [==============================] - 1s 716us/step - loss: 0.5988 - acc: 0.7310\n",
      "Epoch 18/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.5891 - acc: 0.7371\n",
      "Epoch 19/500\n",
      "989/989 [==============================] - 1s 841us/step - loss: 0.5805 - acc: 0.7472\n",
      "Epoch 20/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.5722 - acc: 0.7371\n",
      "Epoch 21/500\n",
      "989/989 [==============================] - 1s 936us/step - loss: 0.5633 - acc: 0.7371\n",
      "Epoch 22/500\n",
      "989/989 [==============================] - 1s 913us/step - loss: 0.5546 - acc: 0.7472\n",
      "Epoch 23/500\n",
      "989/989 [==============================] - 1s 755us/step - loss: 0.5472 - acc: 0.7503\n",
      "Epoch 24/500\n",
      "989/989 [==============================] - 1s 870us/step - loss: 0.5407 - acc: 0.7472\n",
      "Epoch 25/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.5324 - acc: 0.7432\n",
      "Epoch 26/500\n",
      "989/989 [==============================] - 1s 739us/step - loss: 0.5268 - acc: 0.7513\n",
      "Epoch 27/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.5207 - acc: 0.7472\n",
      "Epoch 28/500\n",
      "989/989 [==============================] - 1s 836us/step - loss: 0.5157 - acc: 0.7492\n",
      "Epoch 29/500\n",
      "989/989 [==============================] - 1s 880us/step - loss: 0.5124 - acc: 0.7462\n",
      "Epoch 30/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.5070 - acc: 0.7523\n",
      "Epoch 31/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.5028 - acc: 0.7492\n",
      "Epoch 32/500\n",
      "989/989 [==============================] - 1s 905us/step - loss: 0.5002 - acc: 0.7452\n",
      "Epoch 33/500\n",
      "989/989 [==============================] - 1s 733us/step - loss: 0.4972 - acc: 0.7553\n",
      "Epoch 34/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.4929 - acc: 0.7674\n",
      "Epoch 35/500\n",
      "989/989 [==============================] - 1s 703us/step - loss: 0.4898 - acc: 0.7523\n",
      "Epoch 36/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.4889 - acc: 0.7624\n",
      "Epoch 37/500\n",
      "989/989 [==============================] - 1s 791us/step - loss: 0.4856 - acc: 0.7523\n",
      "Epoch 38/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.4844 - acc: 0.7523\n",
      "Epoch 39/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.4823 - acc: 0.7563\n",
      "Epoch 40/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.4851 - acc: 0.7482\n",
      "Epoch 41/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.4783 - acc: 0.7482\n",
      "Epoch 42/500\n",
      "989/989 [==============================] - 2s 2ms/step - loss: 0.4760 - acc: 0.7594\n",
      "Epoch 43/500\n",
      "989/989 [==============================] - 1s 951us/step - loss: 0.4746 - acc: 0.7523\n",
      "Epoch 44/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.4769 - acc: 0.7664\n",
      "Epoch 45/500\n",
      "989/989 [==============================] - 1s 752us/step - loss: 0.4741 - acc: 0.7533\n",
      "Epoch 46/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.4699 - acc: 0.7462\n",
      "Epoch 47/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.4747 - acc: 0.7594\n",
      "Epoch 48/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.4716 - acc: 0.7654\n",
      "Epoch 49/500\n",
      "989/989 [==============================] - 1s 947us/step - loss: 0.4689 - acc: 0.7604\n",
      "Epoch 50/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.4721 - acc: 0.7503\n",
      "Epoch 51/500\n",
      "989/989 [==============================] - 1s 955us/step - loss: 0.4644 - acc: 0.7664\n",
      "Epoch 52/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.4653 - acc: 0.7583\n",
      "Epoch 53/500\n",
      "989/989 [==============================] - 1s 969us/step - loss: 0.4691 - acc: 0.7583\n",
      "Epoch 54/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.4650 - acc: 0.7644\n",
      "Epoch 55/500\n",
      "989/989 [==============================] - 1s 843us/step - loss: 0.4651 - acc: 0.7583\n",
      "Epoch 56/500\n",
      "989/989 [==============================] - 1s 985us/step - loss: 0.4615 - acc: 0.7796\n",
      "Epoch 57/500\n",
      "989/989 [==============================] - 1s 825us/step - loss: 0.4635 - acc: 0.7614\n",
      "Epoch 58/500\n",
      "989/989 [==============================] - 1s 800us/step - loss: 0.4601 - acc: 0.7705\n",
      "Epoch 59/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.4602 - acc: 0.7583\n",
      "Epoch 60/500\n",
      "989/989 [==============================] - 1s 813us/step - loss: 0.4608 - acc: 0.7685\n",
      "Epoch 61/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.4609 - acc: 0.7624\n",
      "Epoch 62/500\n",
      "989/989 [==============================] - 1s 853us/step - loss: 0.4629 - acc: 0.7594\n",
      "Epoch 63/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.4567 - acc: 0.7705\n",
      "Epoch 64/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.4601 - acc: 0.7654\n",
      "Epoch 65/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.4611 - acc: 0.7573\n",
      "Epoch 66/500\n",
      "989/989 [==============================] - 1s 860us/step - loss: 0.4584 - acc: 0.7674\n",
      "Epoch 67/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.4572 - acc: 0.7674\n",
      "Epoch 68/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.4550 - acc: 0.7654\n",
      "Epoch 69/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.4567 - acc: 0.7634\n",
      "Epoch 70/500\n",
      "989/989 [==============================] - 1s 988us/step - loss: 0.4489 - acc: 0.7695\n",
      "Epoch 71/500\n",
      "989/989 [==============================] - 1s 987us/step - loss: 0.4522 - acc: 0.7695\n",
      "Epoch 72/500\n",
      "989/989 [==============================] - 1s 925us/step - loss: 0.4532 - acc: 0.7614\n",
      "Epoch 73/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.4539 - acc: 0.7695\n",
      "Epoch 74/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.4554 - acc: 0.7604\n",
      "Epoch 75/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.4529 - acc: 0.7624\n",
      "Epoch 76/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.4491 - acc: 0.7816\n",
      "Epoch 77/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.4539 - acc: 0.7644\n",
      "Epoch 78/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.4519 - acc: 0.7745\n",
      "Epoch 79/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.4495 - acc: 0.7725\n",
      "Epoch 80/500\n",
      "989/989 [==============================] - 1s 832us/step - loss: 0.4468 - acc: 0.7695\n",
      "Epoch 81/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.4518 - acc: 0.7695\n",
      "Epoch 82/500\n",
      "989/989 [==============================] - 1s 723us/step - loss: 0.4480 - acc: 0.7705\n",
      "Epoch 83/500\n",
      "989/989 [==============================] - 1s 638us/step - loss: 0.4488 - acc: 0.7725\n",
      "Epoch 84/500\n",
      "989/989 [==============================] - 1s 966us/step - loss: 0.4494 - acc: 0.7634\n",
      "Epoch 85/500\n",
      "989/989 [==============================] - 1s 598us/step - loss: 0.4447 - acc: 0.7806\n",
      "Epoch 86/500\n",
      "989/989 [==============================] - 1s 617us/step - loss: 0.4446 - acc: 0.7786\n",
      "Epoch 87/500\n",
      "989/989 [==============================] - 1s 906us/step - loss: 0.4414 - acc: 0.7685\n",
      "Epoch 88/500\n",
      "989/989 [==============================] - 1s 829us/step - loss: 0.4442 - acc: 0.7786\n",
      "Epoch 89/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.4415 - acc: 0.7695\n",
      "Epoch 90/500\n",
      "989/989 [==============================] - 1s 676us/step - loss: 0.4366 - acc: 0.7846\n",
      "Epoch 91/500\n",
      "989/989 [==============================] - 1s 666us/step - loss: 0.4470 - acc: 0.7796\n",
      "Epoch 92/500\n",
      "989/989 [==============================] - 1s 888us/step - loss: 0.4414 - acc: 0.7725\n",
      "Epoch 93/500\n",
      "989/989 [==============================] - 1s 617us/step - loss: 0.4419 - acc: 0.7826\n",
      "Epoch 94/500\n",
      "989/989 [==============================] - 1s 609us/step - loss: 0.4414 - acc: 0.7856\n",
      "Epoch 95/500\n",
      "989/989 [==============================] - 1s 787us/step - loss: 0.4364 - acc: 0.7796\n",
      "Epoch 96/500\n",
      "989/989 [==============================] - 1s 754us/step - loss: 0.4376 - acc: 0.7735\n",
      "Epoch 97/500\n",
      "989/989 [==============================] - 1s 787us/step - loss: 0.4430 - acc: 0.7806\n",
      "Epoch 98/500\n",
      "989/989 [==============================] - 1s 898us/step - loss: 0.4409 - acc: 0.7765\n",
      "Epoch 99/500\n",
      "989/989 [==============================] - 1s 886us/step - loss: 0.4353 - acc: 0.7856\n",
      "Epoch 100/500\n",
      "989/989 [==============================] - 1s 688us/step - loss: 0.4327 - acc: 0.7816\n",
      "Epoch 101/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.4377 - acc: 0.7755\n",
      "Epoch 102/500\n",
      "989/989 [==============================] - 1s 825us/step - loss: 0.4370 - acc: 0.7745\n",
      "Epoch 103/500\n",
      "989/989 [==============================] - 1s 900us/step - loss: 0.4348 - acc: 0.7806\n",
      "Epoch 104/500\n",
      "989/989 [==============================] - 1s 807us/step - loss: 0.4318 - acc: 0.7867\n",
      "Epoch 105/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.4333 - acc: 0.7705\n",
      "Epoch 106/500\n",
      "989/989 [==============================] - 1s 694us/step - loss: 0.4349 - acc: 0.7776\n",
      "Epoch 107/500\n",
      "989/989 [==============================] - 1s 629us/step - loss: 0.4325 - acc: 0.7786\n",
      "Epoch 108/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.4286 - acc: 0.7856\n",
      "Epoch 109/500\n",
      "989/989 [==============================] - 1s 628us/step - loss: 0.4292 - acc: 0.7776\n",
      "Epoch 110/500\n",
      "989/989 [==============================] - 1s 676us/step - loss: 0.4342 - acc: 0.7796\n",
      "Epoch 111/500\n",
      "989/989 [==============================] - 1s 942us/step - loss: 0.4267 - acc: 0.7826\n",
      "Epoch 112/500\n",
      "989/989 [==============================] - 1s 681us/step - loss: 0.4312 - acc: 0.7816\n",
      "Epoch 113/500\n",
      "989/989 [==============================] - 1s 676us/step - loss: 0.4295 - acc: 0.7907\n",
      "Epoch 114/500\n",
      "989/989 [==============================] - 1s 977us/step - loss: 0.4244 - acc: 0.7907\n",
      "Epoch 115/500\n",
      "989/989 [==============================] - 1s 694us/step - loss: 0.4314 - acc: 0.7826\n",
      "Epoch 116/500\n",
      "989/989 [==============================] - 1s 673us/step - loss: 0.4296 - acc: 0.7776\n",
      "Epoch 117/500\n",
      "989/989 [==============================] - 1s 836us/step - loss: 0.4240 - acc: 0.7856\n",
      "Epoch 118/500\n",
      "989/989 [==============================] - 1s 642us/step - loss: 0.4226 - acc: 0.7907\n",
      "Epoch 119/500\n",
      "989/989 [==============================] - 1s 671us/step - loss: 0.4240 - acc: 0.7978\n",
      "Epoch 120/500\n",
      "989/989 [==============================] - 1s 836us/step - loss: 0.4259 - acc: 0.7836\n",
      "Epoch 121/500\n",
      "989/989 [==============================] - 1s 688us/step - loss: 0.4261 - acc: 0.7887\n",
      "Epoch 122/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.4257 - acc: 0.7846\n",
      "Epoch 123/500\n",
      "989/989 [==============================] - 1s 976us/step - loss: 0.4245 - acc: 0.7786\n",
      "Epoch 124/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.4199 - acc: 0.7897\n",
      "Epoch 125/500\n",
      "989/989 [==============================] - 1s 913us/step - loss: 0.4207 - acc: 0.7947\n",
      "Epoch 126/500\n",
      "989/989 [==============================] - 1s 740us/step - loss: 0.4191 - acc: 0.7927\n",
      "Epoch 127/500\n",
      "989/989 [==============================] - 1s 832us/step - loss: 0.4184 - acc: 0.7897\n",
      "Epoch 128/500\n",
      "989/989 [==============================] - 1s 813us/step - loss: 0.4142 - acc: 0.7927\n",
      "Epoch 129/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.4175 - acc: 0.7917\n",
      "Epoch 130/500\n",
      "989/989 [==============================] - 1s 704us/step - loss: 0.4160 - acc: 0.7917\n",
      "Epoch 131/500\n",
      "989/989 [==============================] - 1s 678us/step - loss: 0.4198 - acc: 0.7917\n",
      "Epoch 132/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.4112 - acc: 0.8018\n",
      "Epoch 133/500\n",
      "989/989 [==============================] - 1s 643us/step - loss: 0.4212 - acc: 0.7806\n",
      "Epoch 134/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.4164 - acc: 0.8018\n",
      "Epoch 135/500\n",
      "989/989 [==============================] - 1s 738us/step - loss: 0.4148 - acc: 0.7907\n",
      "Epoch 136/500\n",
      "989/989 [==============================] - 1s 639us/step - loss: 0.4132 - acc: 0.8109\n",
      "Epoch 137/500\n",
      "989/989 [==============================] - 1s 872us/step - loss: 0.4124 - acc: 0.7867\n",
      "Epoch 138/500\n",
      "989/989 [==============================] - 1s 718us/step - loss: 0.4082 - acc: 0.7998\n",
      "Epoch 139/500\n",
      "989/989 [==============================] - 1s 708us/step - loss: 0.4139 - acc: 0.7856\n",
      "Epoch 140/500\n",
      "989/989 [==============================] - 1s 869us/step - loss: 0.4114 - acc: 0.7927\n",
      "Epoch 141/500\n",
      "989/989 [==============================] - 1s 627us/step - loss: 0.4156 - acc: 0.7867\n",
      "Epoch 142/500\n",
      "989/989 [==============================] - 1s 606us/step - loss: 0.4076 - acc: 0.7867\n",
      "Epoch 143/500\n",
      "989/989 [==============================] - 1s 874us/step - loss: 0.4092 - acc: 0.8008\n",
      "Epoch 144/500\n",
      "989/989 [==============================] - 1s 821us/step - loss: 0.4080 - acc: 0.8028\n",
      "Epoch 145/500\n",
      "989/989 [==============================] - 1s 886us/step - loss: 0.4140 - acc: 0.7907\n",
      "Epoch 146/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.4124 - acc: 0.7897\n",
      "Epoch 147/500\n",
      "989/989 [==============================] - 1s 845us/step - loss: 0.4094 - acc: 0.7958\n",
      "Epoch 148/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.4060 - acc: 0.8059\n",
      "Epoch 149/500\n",
      "989/989 [==============================] - 1s 798us/step - loss: 0.4081 - acc: 0.7988\n",
      "Epoch 150/500\n",
      "989/989 [==============================] - 1s 654us/step - loss: 0.4106 - acc: 0.7846\n",
      "Epoch 151/500\n",
      "989/989 [==============================] - 1s 945us/step - loss: 0.4084 - acc: 0.7917\n",
      "Epoch 152/500\n",
      "989/989 [==============================] - 1s 734us/step - loss: 0.4031 - acc: 0.7988\n",
      "Epoch 153/500\n",
      "989/989 [==============================] - 1s 875us/step - loss: 0.4053 - acc: 0.7887\n",
      "Epoch 154/500\n",
      "989/989 [==============================] - 1s 840us/step - loss: 0.3996 - acc: 0.8028\n",
      "Epoch 155/500\n",
      "989/989 [==============================] - 1s 979us/step - loss: 0.4029 - acc: 0.8028\n",
      "Epoch 156/500\n",
      "989/989 [==============================] - 1s 952us/step - loss: 0.4065 - acc: 0.8008\n",
      "Epoch 157/500\n",
      "989/989 [==============================] - 1s 785us/step - loss: 0.4032 - acc: 0.8038\n",
      "Epoch 158/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3999 - acc: 0.8008\n",
      "Epoch 159/500\n",
      "989/989 [==============================] - 1s 932us/step - loss: 0.4048 - acc: 0.7937\n",
      "Epoch 160/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.4024 - acc: 0.7937\n",
      "Epoch 161/500\n",
      "989/989 [==============================] - 1s 854us/step - loss: 0.3972 - acc: 0.8038\n",
      "Epoch 162/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.4033 - acc: 0.7968\n",
      "Epoch 163/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "989/989 [==============================] - 1s 785us/step - loss: 0.4049 - acc: 0.7998\n",
      "Epoch 164/500\n",
      "989/989 [==============================] - 1s 780us/step - loss: 0.3952 - acc: 0.8059\n",
      "Epoch 165/500\n",
      "989/989 [==============================] - 1s 932us/step - loss: 0.4016 - acc: 0.8008\n",
      "Epoch 166/500\n",
      "989/989 [==============================] - 1s 757us/step - loss: 0.3934 - acc: 0.8049\n",
      "Epoch 167/500\n",
      "989/989 [==============================] - 1s 634us/step - loss: 0.3978 - acc: 0.7937\n",
      "Epoch 168/500\n",
      "989/989 [==============================] - 1s 900us/step - loss: 0.3999 - acc: 0.8140\n",
      "Epoch 169/500\n",
      "989/989 [==============================] - 1s 599us/step - loss: 0.3974 - acc: 0.8059\n",
      "Epoch 170/500\n",
      "989/989 [==============================] - 1s 587us/step - loss: 0.4004 - acc: 0.7978\n",
      "Epoch 171/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3934 - acc: 0.8099\n",
      "Epoch 172/500\n",
      "989/989 [==============================] - 1s 868us/step - loss: 0.3997 - acc: 0.7978\n",
      "Epoch 173/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3904 - acc: 0.8049\n",
      "Epoch 174/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3914 - acc: 0.8018\n",
      "Epoch 175/500\n",
      "989/989 [==============================] - 1s 832us/step - loss: 0.3978 - acc: 0.7988\n",
      "Epoch 176/500\n",
      "989/989 [==============================] - 1s 659us/step - loss: 0.3957 - acc: 0.7978\n",
      "Epoch 177/500\n",
      "989/989 [==============================] - 1s 925us/step - loss: 0.3944 - acc: 0.7998\n",
      "Epoch 178/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3924 - acc: 0.8089\n",
      "Epoch 179/500\n",
      "989/989 [==============================] - 1s 747us/step - loss: 0.3958 - acc: 0.7988\n",
      "Epoch 180/500\n",
      "989/989 [==============================] - 1s 859us/step - loss: 0.3951 - acc: 0.7978\n",
      "Epoch 181/500\n",
      "989/989 [==============================] - 1s 840us/step - loss: 0.3997 - acc: 0.8018\n",
      "Epoch 182/500\n",
      "989/989 [==============================] - 1s 984us/step - loss: 0.3877 - acc: 0.8180\n",
      "Epoch 183/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3911 - acc: 0.8028\n",
      "Epoch 184/500\n",
      "989/989 [==============================] - 1s 810us/step - loss: 0.3909 - acc: 0.8049\n",
      "Epoch 185/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3909 - acc: 0.7988\n",
      "Epoch 186/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3948 - acc: 0.8028\n",
      "Epoch 187/500\n",
      "989/989 [==============================] - 1s 800us/step - loss: 0.3816 - acc: 0.8099\n",
      "Epoch 188/500\n",
      "989/989 [==============================] - 1s 665us/step - loss: 0.3897 - acc: 0.8049\n",
      "Epoch 189/500\n",
      "989/989 [==============================] - 1s 733us/step - loss: 0.3922 - acc: 0.8038\n",
      "Epoch 190/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3868 - acc: 0.8099\n",
      "Epoch 191/500\n",
      "989/989 [==============================] - 1s 779us/step - loss: 0.3917 - acc: 0.8038\n",
      "Epoch 192/500\n",
      "989/989 [==============================] - 1s 621us/step - loss: 0.3860 - acc: 0.8089\n",
      "Epoch 193/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3871 - acc: 0.8018\n",
      "Epoch 194/500\n",
      "989/989 [==============================] - 1s 669us/step - loss: 0.3882 - acc: 0.8170\n",
      "Epoch 195/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3886 - acc: 0.8109\n",
      "Epoch 196/500\n",
      "989/989 [==============================] - 1s 902us/step - loss: 0.3835 - acc: 0.8008\n",
      "Epoch 197/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3835 - acc: 0.8170\n",
      "Epoch 198/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3838 - acc: 0.8069\n",
      "Epoch 199/500\n",
      "989/989 [==============================] - 1s 866us/step - loss: 0.3811 - acc: 0.8109\n",
      "Epoch 200/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3780 - acc: 0.8059\n",
      "Epoch 201/500\n",
      "989/989 [==============================] - 1s 969us/step - loss: 0.3858 - acc: 0.7927\n",
      "Epoch 202/500\n",
      "989/989 [==============================] - 1s 829us/step - loss: 0.3805 - acc: 0.8150\n",
      "Epoch 203/500\n",
      "989/989 [==============================] - 1s 681us/step - loss: 0.3840 - acc: 0.8018\n",
      "Epoch 204/500\n",
      "989/989 [==============================] - 1s 873us/step - loss: 0.3888 - acc: 0.7937\n",
      "Epoch 205/500\n",
      "989/989 [==============================] - 1s 843us/step - loss: 0.3767 - acc: 0.7998\n",
      "Epoch 206/500\n",
      "989/989 [==============================] - 1s 638us/step - loss: 0.3804 - acc: 0.8170\n",
      "Epoch 207/500\n",
      "989/989 [==============================] - 1s 730us/step - loss: 0.3808 - acc: 0.8069\n",
      "Epoch 208/500\n",
      "989/989 [==============================] - 1s 893us/step - loss: 0.3778 - acc: 0.8180\n",
      "Epoch 209/500\n",
      "989/989 [==============================] - 1s 679us/step - loss: 0.3768 - acc: 0.8099\n",
      "Epoch 210/500\n",
      "989/989 [==============================] - 1s 697us/step - loss: 0.3771 - acc: 0.8170\n",
      "Epoch 211/500\n",
      "989/989 [==============================] - 1s 894us/step - loss: 0.3788 - acc: 0.8099\n",
      "Epoch 212/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3823 - acc: 0.8028\n",
      "Epoch 213/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3770 - acc: 0.7958\n",
      "Epoch 214/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3818 - acc: 0.8089\n",
      "Epoch 215/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3758 - acc: 0.8028\n",
      "Epoch 216/500\n",
      "989/989 [==============================] - 1s 886us/step - loss: 0.3787 - acc: 0.8089\n",
      "Epoch 217/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3748 - acc: 0.8129\n",
      "Epoch 218/500\n",
      "989/989 [==============================] - 1s 948us/step - loss: 0.3749 - acc: 0.8028\n",
      "Epoch 219/500\n",
      "989/989 [==============================] - 1s 687us/step - loss: 0.3749 - acc: 0.8099\n",
      "Epoch 220/500\n",
      "989/989 [==============================] - 1s 915us/step - loss: 0.3693 - acc: 0.8129\n",
      "Epoch 221/500\n",
      "989/989 [==============================] - 1s 732us/step - loss: 0.3753 - acc: 0.8140\n",
      "Epoch 222/500\n",
      "989/989 [==============================] - 1s 902us/step - loss: 0.3764 - acc: 0.8170\n",
      "Epoch 223/500\n",
      "989/989 [==============================] - 1s 691us/step - loss: 0.3721 - acc: 0.8200\n",
      "Epoch 224/500\n",
      "989/989 [==============================] - 1s 693us/step - loss: 0.3710 - acc: 0.8180\n",
      "Epoch 225/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3715 - acc: 0.8220\n",
      "Epoch 226/500\n",
      "989/989 [==============================] - 1s 893us/step - loss: 0.3788 - acc: 0.8018\n",
      "Epoch 227/500\n",
      "989/989 [==============================] - 1s 863us/step - loss: 0.3741 - acc: 0.8160\n",
      "Epoch 228/500\n",
      "989/989 [==============================] - 1s 688us/step - loss: 0.3689 - acc: 0.8099\n",
      "Epoch 229/500\n",
      "989/989 [==============================] - 1s 632us/step - loss: 0.3681 - acc: 0.8089\n",
      "Epoch 230/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3673 - acc: 0.8271\n",
      "Epoch 231/500\n",
      "989/989 [==============================] - 1s 762us/step - loss: 0.3683 - acc: 0.8180\n",
      "Epoch 232/500\n",
      "989/989 [==============================] - 1s 695us/step - loss: 0.3717 - acc: 0.8038\n",
      "Epoch 233/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3685 - acc: 0.8150\n",
      "Epoch 234/500\n",
      "989/989 [==============================] - 1s 606us/step - loss: 0.3681 - acc: 0.8170\n",
      "Epoch 235/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3714 - acc: 0.8220\n",
      "Epoch 236/500\n",
      "989/989 [==============================] - 1s 685us/step - loss: 0.3695 - acc: 0.8109\n",
      "Epoch 237/500\n",
      "989/989 [==============================] - 1s 667us/step - loss: 0.3643 - acc: 0.8190\n",
      "Epoch 238/500\n",
      "989/989 [==============================] - 1s 933us/step - loss: 0.3700 - acc: 0.8038\n",
      "Epoch 239/500\n",
      "989/989 [==============================] - 1s 913us/step - loss: 0.3615 - acc: 0.8180\n",
      "Epoch 240/500\n",
      "989/989 [==============================] - 1s 725us/step - loss: 0.3675 - acc: 0.8049\n",
      "Epoch 241/500\n",
      "989/989 [==============================] - 1s 985us/step - loss: 0.3638 - acc: 0.8210\n",
      "Epoch 242/500\n",
      "989/989 [==============================] - 1s 831us/step - loss: 0.3688 - acc: 0.8079\n",
      "Epoch 243/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3665 - acc: 0.8220\n",
      "Epoch 244/500\n",
      "989/989 [==============================] - 1s 848us/step - loss: 0.3621 - acc: 0.8251\n",
      "Epoch 245/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3650 - acc: 0.8170\n",
      "Epoch 246/500\n",
      "989/989 [==============================] - 1s 711us/step - loss: 0.3692 - acc: 0.8089\n",
      "Epoch 247/500\n",
      "989/989 [==============================] - 1s 819us/step - loss: 0.3650 - acc: 0.8069\n",
      "Epoch 248/500\n",
      "989/989 [==============================] - 1s 864us/step - loss: 0.3595 - acc: 0.8291\n",
      "Epoch 249/500\n",
      "989/989 [==============================] - 1s 663us/step - loss: 0.3571 - acc: 0.8069\n",
      "Epoch 250/500\n",
      "989/989 [==============================] - 1s 625us/step - loss: 0.3628 - acc: 0.8271\n",
      "Epoch 251/500\n",
      "989/989 [==============================] - 1s 906us/step - loss: 0.3589 - acc: 0.8129\n",
      "Epoch 252/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3638 - acc: 0.8129\n",
      "Epoch 253/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3612 - acc: 0.8109\n",
      "Epoch 254/500\n",
      "989/989 [==============================] - 1s 834us/step - loss: 0.3625 - acc: 0.8170\n",
      "Epoch 255/500\n",
      "989/989 [==============================] - 1s 767us/step - loss: 0.3560 - acc: 0.8261\n",
      "Epoch 256/500\n",
      "989/989 [==============================] - 1s 979us/step - loss: 0.3632 - acc: 0.8160\n",
      "Epoch 257/500\n",
      "989/989 [==============================] - 1s 786us/step - loss: 0.3652 - acc: 0.8109\n",
      "Epoch 258/500\n",
      "989/989 [==============================] - 1s 608us/step - loss: 0.3580 - acc: 0.8210\n",
      "Epoch 259/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3638 - acc: 0.8241\n",
      "Epoch 260/500\n",
      "989/989 [==============================] - 1s 727us/step - loss: 0.3625 - acc: 0.8150 0s - loss: 0.3379 -\n",
      "Epoch 261/500\n",
      "989/989 [==============================] - 1s 991us/step - loss: 0.3568 - acc: 0.8180\n",
      "Epoch 262/500\n",
      "989/989 [==============================] - 1s 844us/step - loss: 0.3528 - acc: 0.8150\n",
      "Epoch 263/500\n",
      "989/989 [==============================] - 1s 580us/step - loss: 0.3614 - acc: 0.8190\n",
      "Epoch 264/500\n",
      "989/989 [==============================] - 1s 894us/step - loss: 0.3554 - acc: 0.8261\n",
      "Epoch 265/500\n",
      "989/989 [==============================] - 1s 651us/step - loss: 0.3545 - acc: 0.8281\n",
      "Epoch 266/500\n",
      "989/989 [==============================] - 1s 584us/step - loss: 0.3544 - acc: 0.8322\n",
      "Epoch 267/500\n",
      "989/989 [==============================] - 1s 878us/step - loss: 0.3550 - acc: 0.8220\n",
      "Epoch 268/500\n",
      "989/989 [==============================] - 1s 629us/step - loss: 0.3562 - acc: 0.8301\n",
      "Epoch 269/500\n",
      "989/989 [==============================] - 1s 698us/step - loss: 0.3515 - acc: 0.8180\n",
      "Epoch 270/500\n",
      "989/989 [==============================] - 1s 980us/step - loss: 0.3578 - acc: 0.8190\n",
      "Epoch 271/500\n",
      "989/989 [==============================] - 1s 770us/step - loss: 0.3546 - acc: 0.8231\n",
      "Epoch 272/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3565 - acc: 0.8261\n",
      "Epoch 273/500\n",
      "989/989 [==============================] - 1s 692us/step - loss: 0.3538 - acc: 0.8200\n",
      "Epoch 274/500\n",
      "989/989 [==============================] - 1s 824us/step - loss: 0.3566 - acc: 0.8220\n",
      "Epoch 275/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3543 - acc: 0.8129\n",
      "Epoch 276/500\n",
      "989/989 [==============================] - 1s 852us/step - loss: 0.3582 - acc: 0.8160\n",
      "Epoch 277/500\n",
      "989/989 [==============================] - 1s 662us/step - loss: 0.3497 - acc: 0.8332\n",
      "Epoch 278/500\n",
      "989/989 [==============================] - 1s 957us/step - loss: 0.3551 - acc: 0.8291\n",
      "Epoch 279/500\n",
      "989/989 [==============================] - 1s 713us/step - loss: 0.3518 - acc: 0.8261\n",
      "Epoch 280/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3507 - acc: 0.8281\n",
      "Epoch 281/500\n",
      "989/989 [==============================] - 1s 868us/step - loss: 0.3451 - acc: 0.8281\n",
      "Epoch 282/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3546 - acc: 0.8210\n",
      "Epoch 283/500\n",
      "989/989 [==============================] - 1s 915us/step - loss: 0.3525 - acc: 0.8150\n",
      "Epoch 284/500\n",
      "989/989 [==============================] - 1s 879us/step - loss: 0.3524 - acc: 0.8109\n",
      "Epoch 285/500\n",
      "989/989 [==============================] - 1s 962us/step - loss: 0.3504 - acc: 0.8332\n",
      "Epoch 286/500\n",
      "989/989 [==============================] - 1s 941us/step - loss: 0.3486 - acc: 0.8261\n",
      "Epoch 287/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3462 - acc: 0.8311\n",
      "Epoch 288/500\n",
      "989/989 [==============================] - 1s 918us/step - loss: 0.3503 - acc: 0.8231\n",
      "Epoch 289/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3495 - acc: 0.8261\n",
      "Epoch 290/500\n",
      "989/989 [==============================] - 1s 692us/step - loss: 0.3473 - acc: 0.8301\n",
      "Epoch 291/500\n",
      "989/989 [==============================] - 1s 672us/step - loss: 0.3503 - acc: 0.8332\n",
      "Epoch 292/500\n",
      "989/989 [==============================] - 1s 892us/step - loss: 0.3511 - acc: 0.8190\n",
      "Epoch 293/500\n",
      "989/989 [==============================] - 1s 687us/step - loss: 0.3481 - acc: 0.8291\n",
      "Epoch 294/500\n",
      "989/989 [==============================] - 1s 662us/step - loss: 0.3569 - acc: 0.8200\n",
      "Epoch 295/500\n",
      "989/989 [==============================] - 1s 897us/step - loss: 0.3469 - acc: 0.8332\n",
      "Epoch 296/500\n",
      "989/989 [==============================] - 1s 662us/step - loss: 0.3456 - acc: 0.8261\n",
      "Epoch 297/500\n",
      "989/989 [==============================] - 1s 631us/step - loss: 0.3466 - acc: 0.8402\n",
      "Epoch 298/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3500 - acc: 0.8241\n",
      "Epoch 299/500\n",
      "989/989 [==============================] - 1s 738us/step - loss: 0.3459 - acc: 0.8392\n",
      "Epoch 300/500\n",
      "989/989 [==============================] - 1s 841us/step - loss: 0.3412 - acc: 0.8271\n",
      "Epoch 301/500\n",
      "989/989 [==============================] - 1s 972us/step - loss: 0.3477 - acc: 0.8271\n",
      "Epoch 302/500\n",
      "989/989 [==============================] - 1s 809us/step - loss: 0.3401 - acc: 0.8372\n",
      "Epoch 303/500\n",
      "989/989 [==============================] - 1s 968us/step - loss: 0.3414 - acc: 0.8180\n",
      "Epoch 304/500\n",
      "989/989 [==============================] - 1s 772us/step - loss: 0.3441 - acc: 0.8311\n",
      "Epoch 305/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3404 - acc: 0.8311\n",
      "Epoch 306/500\n",
      "989/989 [==============================] - 1s 779us/step - loss: 0.3447 - acc: 0.8129\n",
      "Epoch 307/500\n",
      "989/989 [==============================] - 1s 857us/step - loss: 0.3499 - acc: 0.8099\n",
      "Epoch 308/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3439 - acc: 0.8332\n",
      "Epoch 309/500\n",
      "989/989 [==============================] - 1s 697us/step - loss: 0.3402 - acc: 0.8352\n",
      "Epoch 310/500\n",
      "989/989 [==============================] - 1s 862us/step - loss: 0.3361 - acc: 0.8382\n",
      "Epoch 311/500\n",
      "989/989 [==============================] - 1s 707us/step - loss: 0.3370 - acc: 0.8342\n",
      "Epoch 312/500\n",
      "989/989 [==============================] - 1s 759us/step - loss: 0.3399 - acc: 0.8352\n",
      "Epoch 313/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3430 - acc: 0.8231\n",
      "Epoch 314/500\n",
      "989/989 [==============================] - 1s 855us/step - loss: 0.3377 - acc: 0.8301\n",
      "Epoch 315/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3406 - acc: 0.8402\n",
      "Epoch 316/500\n",
      "989/989 [==============================] - 1s 763us/step - loss: 0.3398 - acc: 0.8301\n",
      "Epoch 317/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3396 - acc: 0.8231\n",
      "Epoch 318/500\n",
      "989/989 [==============================] - 1s 880us/step - loss: 0.3369 - acc: 0.8372\n",
      "Epoch 319/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3369 - acc: 0.8301\n",
      "Epoch 320/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3400 - acc: 0.8301\n",
      "Epoch 321/500\n",
      "989/989 [==============================] - 1s 713us/step - loss: 0.3395 - acc: 0.8433\n",
      "Epoch 322/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3353 - acc: 0.8332\n",
      "Epoch 323/500\n",
      "989/989 [==============================] - 1s 937us/step - loss: 0.3348 - acc: 0.8332\n",
      "Epoch 324/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3331 - acc: 0.8423\n",
      "Epoch 325/500\n",
      "989/989 [==============================] - 1s 768us/step - loss: 0.3353 - acc: 0.8382\n",
      "Epoch 326/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3404 - acc: 0.8291\n",
      "Epoch 327/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "989/989 [==============================] - 1s 612us/step - loss: 0.3347 - acc: 0.8372\n",
      "Epoch 328/500\n",
      "989/989 [==============================] - 1s 673us/step - loss: 0.3330 - acc: 0.8261\n",
      "Epoch 329/500\n",
      "989/989 [==============================] - 1s 860us/step - loss: 0.3331 - acc: 0.8342\n",
      "Epoch 330/500\n",
      "989/989 [==============================] - 1s 667us/step - loss: 0.3311 - acc: 0.8311\n",
      "Epoch 331/500\n",
      "989/989 [==============================] - 1s 648us/step - loss: 0.3314 - acc: 0.8281\n",
      "Epoch 332/500\n",
      "989/989 [==============================] - 1s 868us/step - loss: 0.3335 - acc: 0.8433\n",
      "Epoch 333/500\n",
      "989/989 [==============================] - 1s 674us/step - loss: 0.3352 - acc: 0.8402\n",
      "Epoch 334/500\n",
      "989/989 [==============================] - 1s 625us/step - loss: 0.3375 - acc: 0.8231\n",
      "Epoch 335/500\n",
      "989/989 [==============================] - 1s 874us/step - loss: 0.3332 - acc: 0.8271\n",
      "Epoch 336/500\n",
      "989/989 [==============================] - 1s 631us/step - loss: 0.3332 - acc: 0.8281\n",
      "Epoch 337/500\n",
      "989/989 [==============================] - 1s 679us/step - loss: 0.3354 - acc: 0.8372\n",
      "Epoch 338/500\n",
      "989/989 [==============================] - 1s 864us/step - loss: 0.3335 - acc: 0.8291\n",
      "Epoch 339/500\n",
      "989/989 [==============================] - 1s 857us/step - loss: 0.3348 - acc: 0.8261\n",
      "Epoch 340/500\n",
      "989/989 [==============================] - 1s 574us/step - loss: 0.3291 - acc: 0.8402\n",
      "Epoch 341/500\n",
      "989/989 [==============================] - 1s 828us/step - loss: 0.3298 - acc: 0.8402\n",
      "Epoch 342/500\n",
      "989/989 [==============================] - 1s 620us/step - loss: 0.3296 - acc: 0.8382\n",
      "Epoch 343/500\n",
      "989/989 [==============================] - 1s 621us/step - loss: 0.3224 - acc: 0.8433\n",
      "Epoch 344/500\n",
      "989/989 [==============================] - 1s 588us/step - loss: 0.3307 - acc: 0.8311\n",
      "Epoch 345/500\n",
      "989/989 [==============================] - 1s 805us/step - loss: 0.3307 - acc: 0.8362\n",
      "Epoch 346/500\n",
      "989/989 [==============================] - 1s 677us/step - loss: 0.3236 - acc: 0.8554\n",
      "Epoch 347/500\n",
      "989/989 [==============================] - 1s 675us/step - loss: 0.3322 - acc: 0.8453\n",
      "Epoch 348/500\n",
      "989/989 [==============================] - 1s 842us/step - loss: 0.3358 - acc: 0.8251\n",
      "Epoch 349/500\n",
      "989/989 [==============================] - 1s 650us/step - loss: 0.3287 - acc: 0.8463\n",
      "Epoch 350/500\n",
      "989/989 [==============================] - 1s 694us/step - loss: 0.3332 - acc: 0.8352\n",
      "Epoch 351/500\n",
      "989/989 [==============================] - 1s 835us/step - loss: 0.3298 - acc: 0.8382\n",
      "Epoch 352/500\n",
      "989/989 [==============================] - 1s 676us/step - loss: 0.3275 - acc: 0.8493\n",
      "Epoch 353/500\n",
      "989/989 [==============================] - 1s 678us/step - loss: 0.3311 - acc: 0.8372\n",
      "Epoch 354/500\n",
      "989/989 [==============================] - 1s 875us/step - loss: 0.3304 - acc: 0.8332\n",
      "Epoch 355/500\n",
      "989/989 [==============================] - 1s 778us/step - loss: 0.3292 - acc: 0.8504\n",
      "Epoch 356/500\n",
      "989/989 [==============================] - 1s 804us/step - loss: 0.3236 - acc: 0.8402\n",
      "Epoch 357/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3325 - acc: 0.8372\n",
      "Epoch 358/500\n",
      "989/989 [==============================] - 1s 804us/step - loss: 0.3281 - acc: 0.8413\n",
      "Epoch 359/500\n",
      "989/989 [==============================] - 1s 949us/step - loss: 0.3233 - acc: 0.8453\n",
      "Epoch 360/500\n",
      "989/989 [==============================] - 1s 851us/step - loss: 0.3235 - acc: 0.8413\n",
      "Epoch 361/500\n",
      "989/989 [==============================] - 1s 949us/step - loss: 0.3228 - acc: 0.8443\n",
      "Epoch 362/500\n",
      "989/989 [==============================] - 1s 710us/step - loss: 0.3244 - acc: 0.8402\n",
      "Epoch 363/500\n",
      "989/989 [==============================] - 1s 736us/step - loss: 0.3232 - acc: 0.8433\n",
      "Epoch 364/500\n",
      "989/989 [==============================] - 1s 914us/step - loss: 0.3251 - acc: 0.8402\n",
      "Epoch 365/500\n",
      "989/989 [==============================] - 1s 814us/step - loss: 0.3268 - acc: 0.8362\n",
      "Epoch 366/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3322 - acc: 0.8352\n",
      "Epoch 367/500\n",
      "989/989 [==============================] - 1s 678us/step - loss: 0.3246 - acc: 0.8301\n",
      "Epoch 368/500\n",
      "989/989 [==============================] - 1s 680us/step - loss: 0.3220 - acc: 0.8433\n",
      "Epoch 369/500\n",
      "989/989 [==============================] - 1s 935us/step - loss: 0.3206 - acc: 0.8504\n",
      "Epoch 370/500\n",
      "989/989 [==============================] - 1s 682us/step - loss: 0.3187 - acc: 0.8372\n",
      "Epoch 371/500\n",
      "989/989 [==============================] - 1s 782us/step - loss: 0.3210 - acc: 0.8382\n",
      "Epoch 372/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3218 - acc: 0.8402\n",
      "Epoch 373/500\n",
      "989/989 [==============================] - 1s 839us/step - loss: 0.3210 - acc: 0.8382\n",
      "Epoch 374/500\n",
      "989/989 [==============================] - 1s 877us/step - loss: 0.3236 - acc: 0.8372\n",
      "Epoch 375/500\n",
      "989/989 [==============================] - 1s 815us/step - loss: 0.3176 - acc: 0.8392\n",
      "Epoch 376/500\n",
      "989/989 [==============================] - 1s 903us/step - loss: 0.3248 - acc: 0.8423\n",
      "Epoch 377/500\n",
      "989/989 [==============================] - 1s 727us/step - loss: 0.3230 - acc: 0.8402\n",
      "Epoch 378/500\n",
      "989/989 [==============================] - 1s 886us/step - loss: 0.3156 - acc: 0.8514\n",
      "Epoch 379/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3203 - acc: 0.8483\n",
      "Epoch 380/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3208 - acc: 0.8493\n",
      "Epoch 381/500\n",
      "989/989 [==============================] - 1s 854us/step - loss: 0.3207 - acc: 0.8554\n",
      "Epoch 382/500\n",
      "989/989 [==============================] - 1s 732us/step - loss: 0.3230 - acc: 0.8463\n",
      "Epoch 383/500\n",
      "989/989 [==============================] - 1s 874us/step - loss: 0.3188 - acc: 0.8433\n",
      "Epoch 384/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3240 - acc: 0.8402\n",
      "Epoch 385/500\n",
      "989/989 [==============================] - 1s 692us/step - loss: 0.3181 - acc: 0.8443\n",
      "Epoch 386/500\n",
      "989/989 [==============================] - 1s 940us/step - loss: 0.3250 - acc: 0.8402\n",
      "Epoch 387/500\n",
      "989/989 [==============================] - 1s 743us/step - loss: 0.3250 - acc: 0.8413\n",
      "Epoch 388/500\n",
      "989/989 [==============================] - 1s 789us/step - loss: 0.3152 - acc: 0.8473\n",
      "Epoch 389/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3151 - acc: 0.8473\n",
      "Epoch 390/500\n",
      "989/989 [==============================] - 1s 771us/step - loss: 0.3119 - acc: 0.8504\n",
      "Epoch 391/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3234 - acc: 0.8453\n",
      "Epoch 392/500\n",
      "989/989 [==============================] - 1s 912us/step - loss: 0.3116 - acc: 0.8433\n",
      "Epoch 393/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3189 - acc: 0.8453\n",
      "Epoch 394/500\n",
      "989/989 [==============================] - 1s 914us/step - loss: 0.3128 - acc: 0.8534\n",
      "Epoch 395/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3194 - acc: 0.8413\n",
      "Epoch 396/500\n",
      "989/989 [==============================] - 1s 829us/step - loss: 0.3165 - acc: 0.8483\n",
      "Epoch 397/500\n",
      "989/989 [==============================] - 1s 926us/step - loss: 0.3139 - acc: 0.8504\n",
      "Epoch 398/500\n",
      "989/989 [==============================] - 1s 724us/step - loss: 0.3136 - acc: 0.8413\n",
      "Epoch 399/500\n",
      "989/989 [==============================] - 1s 816us/step - loss: 0.3114 - acc: 0.8483\n",
      "Epoch 400/500\n",
      "989/989 [==============================] - 1s 953us/step - loss: 0.3177 - acc: 0.8433\n",
      "Epoch 401/500\n",
      "989/989 [==============================] - 1s 849us/step - loss: 0.3092 - acc: 0.8514\n",
      "Epoch 402/500\n",
      "989/989 [==============================] - 1s 769us/step - loss: 0.3032 - acc: 0.8473\n",
      "Epoch 403/500\n",
      "989/989 [==============================] - 1s 969us/step - loss: 0.3115 - acc: 0.8514\n",
      "Epoch 404/500\n",
      "989/989 [==============================] - 1s 745us/step - loss: 0.3132 - acc: 0.8473\n",
      "Epoch 405/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3051 - acc: 0.8595\n",
      "Epoch 406/500\n",
      "989/989 [==============================] - 1s 775us/step - loss: 0.3086 - acc: 0.8493\n",
      "Epoch 407/500\n",
      "989/989 [==============================] - 1s 834us/step - loss: 0.3092 - acc: 0.8493\n",
      "Epoch 408/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3084 - acc: 0.8504\n",
      "Epoch 409/500\n",
      "989/989 [==============================] - 1s 922us/step - loss: 0.3170 - acc: 0.8372\n",
      "Epoch 410/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3090 - acc: 0.8534\n",
      "Epoch 411/500\n",
      "989/989 [==============================] - 1s 802us/step - loss: 0.3072 - acc: 0.8483\n",
      "Epoch 412/500\n",
      "989/989 [==============================] - 1s 915us/step - loss: 0.3127 - acc: 0.8402\n",
      "Epoch 413/500\n",
      "989/989 [==============================] - 1s 718us/step - loss: 0.3094 - acc: 0.8514\n",
      "Epoch 414/500\n",
      "989/989 [==============================] - 1s 675us/step - loss: 0.3105 - acc: 0.8392\n",
      "Epoch 415/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3002 - acc: 0.8605\n",
      "Epoch 416/500\n",
      "989/989 [==============================] - 1s 674us/step - loss: 0.3122 - acc: 0.8382\n",
      "Epoch 417/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3166 - acc: 0.8362\n",
      "Epoch 418/500\n",
      "989/989 [==============================] - 1s 847us/step - loss: 0.3098 - acc: 0.8473\n",
      "Epoch 419/500\n",
      "989/989 [==============================] - 1s 672us/step - loss: 0.3088 - acc: 0.8493\n",
      "Epoch 420/500\n",
      "989/989 [==============================] - 1s 901us/step - loss: 0.3025 - acc: 0.8433\n",
      "Epoch 421/500\n",
      "989/989 [==============================] - 1s 642us/step - loss: 0.3099 - acc: 0.8372\n",
      "Epoch 422/500\n",
      "989/989 [==============================] - 1s 681us/step - loss: 0.3000 - acc: 0.8665\n",
      "Epoch 423/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3017 - acc: 0.8514\n",
      "Epoch 424/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3030 - acc: 0.8534\n",
      "Epoch 425/500\n",
      "989/989 [==============================] - 1s 892us/step - loss: 0.3094 - acc: 0.8443\n",
      "Epoch 426/500\n",
      "989/989 [==============================] - 1s 604us/step - loss: 0.3057 - acc: 0.8514\n",
      "Epoch 427/500\n",
      "989/989 [==============================] - 1s 683us/step - loss: 0.3031 - acc: 0.8483\n",
      "Epoch 428/500\n",
      "989/989 [==============================] - 1s 855us/step - loss: 0.3095 - acc: 0.8372\n",
      "Epoch 429/500\n",
      "989/989 [==============================] - 1s 731us/step - loss: 0.3039 - acc: 0.8524\n",
      "Epoch 430/500\n",
      "989/989 [==============================] - 1s 744us/step - loss: 0.2995 - acc: 0.8584\n",
      "Epoch 431/500\n",
      "989/989 [==============================] - 1s 818us/step - loss: 0.3048 - acc: 0.8514\n",
      "Epoch 432/500\n",
      "989/989 [==============================] - 1s 784us/step - loss: 0.3052 - acc: 0.8504\n",
      "Epoch 433/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3014 - acc: 0.8544\n",
      "Epoch 434/500\n",
      "989/989 [==============================] - 1s 690us/step - loss: 0.3006 - acc: 0.8574\n",
      "Epoch 435/500\n",
      "989/989 [==============================] - 1s 688us/step - loss: 0.2966 - acc: 0.8584\n",
      "Epoch 436/500\n",
      "989/989 [==============================] - 1s 847us/step - loss: 0.3048 - acc: 0.8574\n",
      "Epoch 437/500\n",
      "989/989 [==============================] - 1s 626us/step - loss: 0.2969 - acc: 0.8635\n",
      "Epoch 438/500\n",
      "989/989 [==============================] - 1s 631us/step - loss: 0.2995 - acc: 0.8544\n",
      "Epoch 439/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3120 - acc: 0.8504\n",
      "Epoch 440/500\n",
      "989/989 [==============================] - 1s 842us/step - loss: 0.3068 - acc: 0.8433\n",
      "Epoch 441/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.2960 - acc: 0.8746\n",
      "Epoch 442/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3030 - acc: 0.8453\n",
      "Epoch 443/500\n",
      "989/989 [==============================] - 1s 598us/step - loss: 0.3000 - acc: 0.8554\n",
      "Epoch 444/500\n",
      "989/989 [==============================] - 1s 939us/step - loss: 0.3018 - acc: 0.8554\n",
      "Epoch 445/500\n",
      "989/989 [==============================] - 1s 750us/step - loss: 0.2955 - acc: 0.8595\n",
      "Epoch 446/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.2990 - acc: 0.8574\n",
      "Epoch 447/500\n",
      "989/989 [==============================] - 1s 701us/step - loss: 0.2987 - acc: 0.8544\n",
      "Epoch 448/500\n",
      "989/989 [==============================] - 1s 745us/step - loss: 0.3050 - acc: 0.8453\n",
      "Epoch 449/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3000 - acc: 0.8524\n",
      "Epoch 450/500\n",
      "989/989 [==============================] - 1s 794us/step - loss: 0.2979 - acc: 0.8493\n",
      "Epoch 451/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3000 - acc: 0.8544\n",
      "Epoch 452/500\n",
      "989/989 [==============================] - 1s 653us/step - loss: 0.3026 - acc: 0.8473\n",
      "Epoch 453/500\n",
      "989/989 [==============================] - 1s 619us/step - loss: 0.2936 - acc: 0.8645\n",
      "Epoch 454/500\n",
      "989/989 [==============================] - 1s 893us/step - loss: 0.3065 - acc: 0.8574\n",
      "Epoch 455/500\n",
      "989/989 [==============================] - 1s 682us/step - loss: 0.2973 - acc: 0.8686\n",
      "Epoch 456/500\n",
      "989/989 [==============================] - 1s 673us/step - loss: 0.3008 - acc: 0.8504\n",
      "Epoch 457/500\n",
      "989/989 [==============================] - 1s 972us/step - loss: 0.2982 - acc: 0.8595\n",
      "Epoch 458/500\n",
      "989/989 [==============================] - 1s 936us/step - loss: 0.3043 - acc: 0.8534\n",
      "Epoch 459/500\n",
      "989/989 [==============================] - 1s 820us/step - loss: 0.2944 - acc: 0.8615\n",
      "Epoch 460/500\n",
      "989/989 [==============================] - 1s 925us/step - loss: 0.3011 - acc: 0.8544\n",
      "Epoch 461/500\n",
      "989/989 [==============================] - 1s 654us/step - loss: 0.2946 - acc: 0.8625\n",
      "Epoch 462/500\n",
      "989/989 [==============================] - 1s 945us/step - loss: 0.2903 - acc: 0.8595\n",
      "Epoch 463/500\n",
      "989/989 [==============================] - 1s 708us/step - loss: 0.2946 - acc: 0.8635\n",
      "Epoch 464/500\n",
      "989/989 [==============================] - 1s 674us/step - loss: 0.2914 - acc: 0.8514\n",
      "Epoch 465/500\n",
      "989/989 [==============================] - 1s 953us/step - loss: 0.2991 - acc: 0.8544\n",
      "Epoch 466/500\n",
      "989/989 [==============================] - 1s 743us/step - loss: 0.3071 - acc: 0.8483\n",
      "Epoch 467/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.3044 - acc: 0.8554\n",
      "Epoch 468/500\n",
      "989/989 [==============================] - 1s 724us/step - loss: 0.2930 - acc: 0.8655\n",
      "Epoch 469/500\n",
      "989/989 [==============================] - 1s 700us/step - loss: 0.2987 - acc: 0.8574\n",
      "Epoch 470/500\n",
      "989/989 [==============================] - 1s 931us/step - loss: 0.2976 - acc: 0.8564\n",
      "Epoch 471/500\n",
      "989/989 [==============================] - 1s 637us/step - loss: 0.2948 - acc: 0.8584\n",
      "Epoch 472/500\n",
      "989/989 [==============================] - 1s 996us/step - loss: 0.2932 - acc: 0.8574\n",
      "Epoch 473/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.2872 - acc: 0.8534\n",
      "Epoch 474/500\n",
      "989/989 [==============================] - 1s 901us/step - loss: 0.2927 - acc: 0.8655\n",
      "Epoch 475/500\n",
      "989/989 [==============================] - 1s 931us/step - loss: 0.2965 - acc: 0.8564\n",
      "Epoch 476/500\n",
      "989/989 [==============================] - 1s 827us/step - loss: 0.2961 - acc: 0.8453\n",
      "Epoch 477/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.2939 - acc: 0.8584\n",
      "Epoch 478/500\n",
      "989/989 [==============================] - 1s 798us/step - loss: 0.2904 - acc: 0.8696\n",
      "Epoch 479/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.2955 - acc: 0.8605\n",
      "Epoch 480/500\n",
      "989/989 [==============================] - 1s 689us/step - loss: 0.2933 - acc: 0.8524\n",
      "Epoch 481/500\n",
      "989/989 [==============================] - 1s 864us/step - loss: 0.2941 - acc: 0.8504\n",
      "Epoch 482/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.2938 - acc: 0.8372\n",
      "Epoch 483/500\n",
      "989/989 [==============================] - 1s 861us/step - loss: 0.2925 - acc: 0.8524\n",
      "Epoch 484/500\n",
      "989/989 [==============================] - 1s 938us/step - loss: 0.2882 - acc: 0.8615\n",
      "Epoch 485/500\n",
      "989/989 [==============================] - 1s 880us/step - loss: 0.2912 - acc: 0.8564\n",
      "Epoch 486/500\n",
      "989/989 [==============================] - 1s 967us/step - loss: 0.2908 - acc: 0.8584\n",
      "Epoch 487/500\n",
      "989/989 [==============================] - 1s 760us/step - loss: 0.2881 - acc: 0.8615\n",
      "Epoch 488/500\n",
      "989/989 [==============================] - 1s 750us/step - loss: 0.2823 - acc: 0.8675\n",
      "Epoch 489/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.2852 - acc: 0.8726\n",
      "Epoch 490/500\n",
      "989/989 [==============================] - 1s 811us/step - loss: 0.2889 - acc: 0.8716\n",
      "Epoch 491/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "989/989 [==============================] - 1s 891us/step - loss: 0.2875 - acc: 0.8554\n",
      "Epoch 492/500\n",
      "989/989 [==============================] - 1s 733us/step - loss: 0.2958 - acc: 0.8554\n",
      "Epoch 493/500\n",
      "989/989 [==============================] - 1s 682us/step - loss: 0.2854 - acc: 0.8625\n",
      "Epoch 494/500\n",
      "989/989 [==============================] - 1s 926us/step - loss: 0.2829 - acc: 0.8716\n",
      "Epoch 495/500\n",
      "989/989 [==============================] - 1s 849us/step - loss: 0.2919 - acc: 0.8534\n",
      "Epoch 496/500\n",
      "989/989 [==============================] - 1s 755us/step - loss: 0.2852 - acc: 0.8645\n",
      "Epoch 497/500\n",
      "989/989 [==============================] - 1s 850us/step - loss: 0.2850 - acc: 0.8665\n",
      "Epoch 498/500\n",
      "989/989 [==============================] - 1s 644us/step - loss: 0.2879 - acc: 0.8544\n",
      "Epoch 499/500\n",
      "989/989 [==============================] - 1s 688us/step - loss: 0.2907 - acc: 0.8534\n",
      "Epoch 500/500\n",
      "989/989 [==============================] - 1s 1ms/step - loss: 0.2834 - acc: 0.8615\n",
      "989/989 [==============================] - 0s 185us/step\n",
      "27\n",
      "84\n"
     ]
    }
   ],
   "source": [
    "dataset=pd.read_csv(\"FeaturesDataset.csv\")\n",
    "x=dataset.iloc[:,0:12].values\n",
    "y=dataset.iloc[:,12].values\n",
    "labelencoder = LabelEncoder()\n",
    "y = labelencoder.fit_transform(y)\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "print(x[0])\n",
    "X_scale = min_max_scaler.fit_transform(x)\n",
    "print(X_scale[0])\n",
    "X_train, X_test, y_train, y_test=train_test_split(X_scale,y, test_size=0.1,random_state=None)\n",
    "model = Sequential([Dense(120, activation='relu', input_shape=(12,)),Dense(120, activation='relu'),Dense(1, activation='sigmoid'),])\n",
    "model.compile(optimizer='sgd',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.fit(X_train, y_train,batch_size=10, epochs=500)\n",
    "trainPercent= model.evaluate(X_train,y_train)\n",
    "trainPercent=float(trainPercent[0])\n",
    "trainPercent=(round(trainPercent,2))*100\n",
    "trainPercent=int(trainPercent)\n",
    "print(trainPercent)\n",
    "y_pred_class = model.predict(X_test)\n",
    "\n",
    "y_pred_class= [ 1 if y>=0.5 else 0 for y in y_pred_class]\n",
    "testPercent=metrics.accuracy_score(y_test, y_pred_class)\n",
    "#testPercent=float(testPercent[0])\n",
    "testPercent=(round(testPercent,2))*100\n",
    "testPercent=int(testPercent)\n",
    "print(testPercent)\n",
    "\n",
    "confusion = metrics.confusion_matrix(y_test, y_pred_class)\n",
    "\n",
    "\n",
    "write_mfeatures=[]\n",
    "sampling_rate,speech_signal = wavfile.read('test.WAV')\n",
    "mfcc_feat=compute_mfcc(speech_signal,sampling_rate)\n",
    "write_feat=mfcc_feat.tolist()[0]\n",
    "x=np.array(write_feat)\n",
    "X_scale = min_max_scaler.fit_transform(x.reshape(12,-1))\n",
    "X_scale=X_scale.reshape(-1,12)\n",
    "#print(X_scale)\n",
    "label1= model.predict([X_scale])\n",
    "#print(label1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scores = cross_val_score(model, X_train, y_train, cv=10)\n",
    "#print (\"Cross-validated scores ANN: \", scores)\n",
    "#print(np.mean(scores))\n",
    "\n",
    "#i=1\n",
    "#kf = KFold(n_splits=10, random_state=0, shuffle=True)\n",
    "#kf.get_n_splits(x)\n",
    "#for train_index, test_index in kf.split(x):\n",
    "\n",
    "    #X_train, X_test = x[train_index],x[test_index]\n",
    "    #y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    #model.fit(X_train, y_train)\n",
    "    #y_pred_class = model.predict(X_test)\n",
    "    #print(\"Cross Validaton \", i ,\" : \",metrics.accuracy_score(y_test, y_pred_class))\n",
    "    #i+=1\n",
    "    #print (confusion_matrix(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scores = cross_val_score(model, x, y, cv=10)\n",
    "#print (\"Cross-validated scores ANN: \", scores)\n",
    "#print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
